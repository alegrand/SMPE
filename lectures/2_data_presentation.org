#+TITLE:     Presentation of Scientific Results
#+AUTHOR:    Arnaud Legrand
#+DATE: Performance Evaluation Lecture
#+STARTUP: beamer overview indent
#+TAGS: noexport(n)
#+LaTeX_CLASS: beamer
#+LaTeX_CLASS_OPTIONS: [11pt,xcolor=dvipsnames,presentation]
#+OPTIONS:   H:3 num:t toc:nil \n:nil @:t ::t |:t ^:nil -:t f:t *:t <:t
#+LATEX_HEADER: \input{org-babel-style-preembule.tex}

#+LaTeX: \input{org-babel-document-preembule.tex}


* List                                                             :noexport:
* Data Visualization
#+BEGIN_EXPORT latex
\def\info{
      \resizebox{\linewidth}{!}{
        \begin{minipage}{1.1\linewidth}
          \small
  $N = 11$ samples\\
  Mean of $X$ = 9.0\\
  Mean of $Y$ = 7.5\\%
  \uncover<2->{Intercept = 3\\
  Slope = 0.5\\
  Res. stdev = 1.237\\}%
  Correlation = 0.816
        \end{minipage}
      }
}
#+END_EXPORT

** Motivation
*** Why do we need to visualize ? The Anscombe's Quartet         :noexport:
#+begin_src R :results output :session :exports none
library(ggplot2)
library(plyr)
library(reshape)
anscombe$idx=1:length(anscombe$x1) 
a = melt(anscombe,id=c("idx"))
a$set=gsub("[^0-9]*","",as.character(a$variable))
a$variable=gsub("[0-9]*","",as.character(a$variable))
a = cast(a, idx+set~variable, mean) 
# library(ggplot2)
# library(dplyr)
# library(tidyr)
# anscombe$idx=1:length(anscombe$x1) 
# a = anscombe %>% gather(variable, value,-idx)
# a$set=gsub("[^0-9]*","",as.character(a$variable))
# a$variable=gsub("[0-9]*","",as.character(a$variable))
# a %>% spread(set,variable)
a = cast(a, idx+set~variable, mean) 
#+end_src

#+RESULTS:
: 
: Attachement du package : ‘reshape’
: 
: The following objects are masked from ‘package:plyr’:
: 
:     rename, round_any
: Erreur : Casting formula contains variables not found in molten data: variable

#+LaTeX: \begin{columns}\begin{column}{.4\linewidth}
#+begin_src R :results output :session :exports output
a1=a[a$set==1,c("x","y")]
a2=a[a$set==2,c("x","y")]
a1
#+end_src

#+RESULTS:
#+begin_example
    x     y
1  10  8.04
5   8  6.95
9  13  7.58
13  9  8.81
17 11  8.33
21 14  9.96
25  6  7.24
29  4  4.26
33 12 10.84
37  7  4.82
41  5  5.68
#+end_example

#+LaTeX: \end{column}\begin{column}{.6\linewidth}
#+begin_src R :results output :session :exports both
summary(a1)
summary(a2)
#+end_src

#+RESULTS:
#+begin_example
       x              y         
 Min.   : 4.0   Min.   : 4.260  
 1st Qu.: 6.5   1st Qu.: 6.315  
 Median : 9.0   Median : 7.580  
 Mean   : 9.0   Mean   : 7.501  
 3rd Qu.:11.5   3rd Qu.: 8.570  
 Max.   :14.0   Max.   :10.840
       x              y        
 Min.   : 4.0   Min.   :3.100  
 1st Qu.: 6.5   1st Qu.:6.695  
 Median : 9.0   Median :8.140  
 Mean   : 9.0   Mean   :7.501  
 3rd Qu.:11.5   3rd Qu.:8.950  
 Max.   :14.0   Max.   :9.260
#+end_example

#+LaTeX: \end{column}\end{columns}

*** Why do we need to visualize ? The Anscombe's Quartet
#+BEGIN_EXPORT latex
  \begin{columns}
    \begin{column}{.25\linewidth}
      $\small
      \begin{array}{|r|r|}\hline
        X^{(1)} & Y^{(1)} \n
        10.00 & 8.04  \n
        8.00  & 6.95  \n
        13.00 & 7.58  \n
        9.00  & 8.81  \n
        11.00 & 8.33  \n
        14.00 & 9.96  \n
        6.00  & 7.24  \n
        4.00  & 4.26  \n
        12.00 & 10.24 \n
        7.00  & 4.82  \n
        5.00  & 5.68  \n
      \end{array}
      $\medskip\\
      \info
    \end{column}
%
    \begin{column}{.25\linewidth}
      \only<4->{
      $\small
      \begin{array}{|r|r|}\hline
        X^{(2)} & Y^{(2)} \n
        10.00 & 9.14  \n
        8.00  & 8.14  \n
        13.00 & 8.74  \n
        9.00  & 8.77  \n
        11.00 & 9.26  \n
        14.00 & 8.10  \n
        6.00  & 6.13  \n
        4.00  & 3.10  \n
        12.00 & 9.13 \n
        7.00  & 7.26  \n
        5.00  & 4.74  \n
      \end{array}
      $\medskip\\
      \info
    }
    \end{column}
%
    \begin{column}{.25\linewidth}
      \only<4->{
      $\small
      \begin{array}{|r|r|}\hline
        X^{(3)} & Y^{(3)} \n
        10.00 & 7.46  \n
        8.00  & 6.77  \n
        13.00 & 12.74  \n
        9.00  & 7.11  \n
        11.00 & 7.81  \n
        14.00 & 8.84  \n
        6.00  & 6.08  \n
        4.00  & 5.39  \n
        12.00 & 8.15 \n
        7.00  & 6.42  \n
        5.00  & 5.73  \n
      \end{array}
      $\medskip\\
      \info
    }
    \end{column}
%
    \begin{column}{.25\linewidth}
      \only<4->{
      $\small
      \begin{array}{|r|r|}\hline
        X^{(4)} & Y^{(4)} \n
        8.00  & 6.58  \n
        8.00  & 5.76  \n
        8.00  & 7.71  \n
        8.00  & 8.84  \n
        8.00  & 8.47  \n
        8.00  & 7.04  \n
        8.00  & 5.25  \n
        19.00 &12.50  \n
        8.00  & 5.56 \n
        8.00  & 7.91  \n
        8.00  & 6.89  \n
      \end{array}
      $\medskip\\
      \info}
    \end{column}
  \end{columns}
  \begin{overlayarea}{1.1\linewidth}{0cm}
    \vspace{-8.2cm}\hspace{.15\linewidth}%
    \only<2-3,5-6>{%
      \begin{minipage}{.84\linewidth}
        \begin{alertblock}{}%
          \begin{columns}
          \null\hspace{-.6cm}%
            \begin{column}{.45\linewidth}
              \begin{block}{Scatter plot}
                \includegraphics<2-3>[width=\linewidth]{images/scat1.pdf}%
                \includegraphics<5-6>[width=\linewidth]{images/scat2.pdf}%
              \end{block}
            \end{column}\hspace{-.15\linewidth}
            \begin{column}{.5\linewidth}
              \small \only<3>{
                \begin{enumerate}
                \item The data set "behaves like" a linear curve with
                  some scatter;
                \item There is no justification for a more complicated
                  model (e.g., quadratic);
                \item There are no outliers;
                \item The vertical spread of the data appears to be of
                  equal height irrespective of the X-value; \\
                  this indicates that the data are equally-precise
                  throughout and so a "regular" (that is,
                  equi-weighted) fit is appropriate.
                \end{enumerate}}%
              \only<6>{
                \begin{enumerate}
                \item data set 1 is clearly linear with some scatter.
                \item data set 2 is clearly quadratic.
                \item data set 3 clearly has an outlier.
                \item data set 4 is obviously the victim of a poor
                  experimental design with a single point far removed
                  from the bulk of the data "wagging the dog".
                \end{enumerate}}
            \end{column}
%            \hspace{-2cm}
          \end{columns}
        \end{alertblock}
      \end{minipage}
    }
  \end{overlayarea}

#+END_EXPORT

*** Problem statement
- All *analysis* we perform rely on (sometimes implicit) *assumptions*. If
  these assumptions do not hold, the analysis will be a *complete
  non-sense*.
- Checking these assumptions is not always easy and sometimes, it may
  even be difficult to *list* all these assumptions and *formally state*
  them.
  #+BEGIN_CENTER
  \textbf{A visualization can help to check these assumptions.}
  #+END_CENTER
- Visual representation resort to our *cognitive faculties* to check
  properties.
  
  The visualization is meant to let us detect *expected and
  unexpected behavior* with respect to a given model.
*** Using the ``right'' representations
- The problem is to represent on a limited space, typically a screen
  with a fixed resolution, a meaningful information about the behavior
  of an application or system.
- $\leadsto$ need to aggregate data and be aware of what information
  loss this incurs.
- Every visualization *emphasizes* some characteristics and
  *hides* others. Being aware of the underlying models helps
  choosing the right representation.
*** Visualization and intuition
- Visualization can also be used to *guide your intuition*.

  Sometimes, you do not know exactly what you are looking for and
  looking at the data just helps.
- Some techniques (*Exploratory Data Analysis*) even build on
  this and propose to summarize main characteristics in
  easy-to-understand form, often with visual graphs, without using a
  statistical model or having formulated a hypothesis.
- \textbf{Use with care}, visualizations always have underlying
   models: when visualization is not adapted, what you may observe may
   be meaningless.

  Such approaches may *help formulating hypothesis* but these hypothesis
  have then to be tested upon new data-sets.  
*** A ``simple'' graphical check for investigating scalability
\small
Plotting $T_p$ versus $p$.
#+BEGIN_EXPORT latex
  \begin{center}
    \begin{overlayarea}{.6\linewidth}{4.4cm}
      \includegraphics<1-2>[width=\linewidth]{images/ipdps_plot_2.pdf}
      \includegraphics<3->[width=\linewidth]{images/ipdps_plot_1.pdf}
    \end{overlayarea}
  \end{center}
  \begin{overlayarea}{\linewidth}{2cm}
    \only<2>{
      \begin{itemize}
      \item y-axis does not start at 0, which makes speedup look more
        impressive\vspace{-.5em}
      \item x-axis is linear with an outlier.
      \end{itemize}
   }%
   \only<4>{
     \begin{itemize}
     \item y-axis uses log-scale\vspace{-.5em}
     \item x-axis is neither linear nor logarithmic so we cannot
       reason about the shape of the curve\vspace{-.5em}
     \end{itemize}
     Say, we want to test for Amhdal's law. Propose a better
     representation.}
  \end{overlayarea}
#+END_EXPORT
*** Graphically checking which alternative is better ?
\small 5 different alternatives (=FT-DWD_2=, =FT-DWD_5=, =FT-DWD_10=,
=RT-DWD=, =RT-BWD=), each tested 10 times.
#+BEGIN_CENTER
\begin{overlayarea}{.6\linewidth}{4cm}
\includegraphics[width=\linewidth]{images/ipdps_plot_3.pdf}
\end{overlayarea}
#+END_CENTER
\pause 
Outcomes have been sorted by increasing value for each alternative and
are then linked together
- The shape of the lines do not make any sense. The lines group
  related values\vspace{-.5em}
- Experiment order does not make any sense and makes it look like
  alternatives have been evaluated in 10 different settings (, which
  suggests the values can be compared with each others for each
  setting)\vspace{-.5em}
Propose a better representation
** Jain, Chapter 10
*** Read the basics
- For all such kind of ``general'' graphs where you summarize the
  results of several experiments, the very least you need to *read* is
  *Jain's book*: *The Art of Computer Systems Performance Analysis*. A new
  edition is expected in sept. 2015
- It has *check lists* for ``Good graphics'', which I made
  more or less available on the lecture's webpage
- It presents the most common pitfalls in data representation
- It will teach how to cheat with your figures\dots
- \dots and how to *detect cheaters*. ;)
*** Guidelines
1. Require minimum effort to the reader: get the message (legends,
   labels, trends, annotations, ...)
2. Maximize information (self-sufficient, clear labels, units, ...)
3. Minimize Ink (avoid cluttered information\dots)
4. Use commonly accepted practices (effect along the y-axis, scales)
5. Avoid Ambiguity (coordinates, scales, colors, only one variable, ...)
#+BEGIN_EXPORT latex
  \begin{center}
    \includegraphics<+>[height=4cm]{images/jain/10-02.jpg}
    \includegraphics<+>[height=4cm]{images/jain/10-03.jpg}
    \includegraphics<+>[height=4cm]{images/jain/10-04.jpg}
    \includegraphics<+>[height=4cm]{images/jain/10-05.jpg}
    \includegraphics<+>[height=4cm]{images/jain/10-06.jpg}
    \includegraphics<+>[height=4cm]{images/jain/10-07.jpg}
    \includegraphics<+>[height=4cm]{images/jain/10-08.jpg}
    \includegraphics<+>[height=4cm]{images/jain/10-13.jpg}
    \includegraphics<+>[height=4cm]{images/jain/10-09.jpg}
    \includegraphics<+>[height=4cm]{images/jain/10-10.jpg}
  \end{center}
#+END_EXPORT
*** What about these ones ?
#+BEGIN_CENTER
#+LaTeX: \includegraphics<+>[height=7cm]{images/jain/10-27.jpg}
#+END_CENTER
*** Use the right tools
- \textbf{R} :: is a system for statistical computation and graphics.
  - Avoid programming with R. Most things can be done with one liners.
  - Excellent graphic support with \textbf{ggplot2}.
  - =knitr= allows to mix R with LaTeX or Markdown. Literate
    programming to ease reproducible research.
- \textbf{Rstudio} :: is an IDE a system for statistical
  computation and graphics. It is easy to use and allows publishing
  on \textbf{rpubs}.
- \textbf{Org-mode} ::  Allows to mix sh, perl, R, \dots within plain text
     documents and export to LaTeX, HTML, ...  
* Needful R Packages by Hadley Wickam
** Plyr And Dplyr
*** plyr: the Split-Apply-Combine Strategy 
Have a look at http://plyr.had.co.nz/09-user/ for a more detailed
introduction. 
#+BEGIN_CENTER
 #+ATTR_LaTeX: :height 6cm
 [[./images/split-apply-combine.png]]
#+END_CENTER
*** plyr: Powerful One-liners
\small
#+BEGIN_SRC R :results output :exports both :session
library(plyr)
mtcars_summarized = ddply(mtcars,c("cyl","carb"), summarize, 
      num = length(wt), wt_mean = mean(wt), wt_sd = sd(wt),
      qsec_mean = mean(qsec), qsec_sd = sd(qsec));
mtcars_summarized
#+END_SRC

#+RESULTS:
#+begin_example
  cyl carb num  wt_mean     wt_sd qsec_mean   qsec_sd
1   4    1   5 2.151000 0.2627118  19.37800 0.6121029
2   4    2   6 2.398000 0.7485412  18.93667 2.2924368
3   6    1   2 3.337500 0.1732412  19.83000 0.5515433
4   6    4   4 3.093750 0.4131460  17.67000 1.1249296
5   6    6   1 2.770000        NA  15.50000        NA
6   8    2   4 3.560000 0.1939502  17.06000 0.1783255
7   8    3   3 3.860000 0.1835756  17.66667 0.3055050
8   8    4   6 4.433167 1.0171431  16.49500 1.4424112
9   8    8   1 3.570000        NA  14.60000        NA
#+end_example

*** dplyr
#+BEGIN_CENTER
  #+LaTeX: {\bf plyr next generation = dplyr}
#+END_CENTER

It's much much faster and more readable. The [[https://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html][/tutorial/]] is great...

#+begin_src R :results output :session :exports both
library(dplyr)
mtcars %>% group_by(cyl,carb) %>%
           select(wt,qsec) %>%
           summarise(num = n(),
       wt_mean = mean(wt), wt_sd = sd(wt),
       qsec_mean = mean(qsec), qsec_sd = sd(qsec)) %>%
           filter(num>=1)   
#+end_src

#+RESULTS:
#+begin_example
 Source: local data frame [9 x 7]
Groups: cyl

  cyl carb num  wt_mean     wt_sd qsec_mean   qsec_sd
1   4    1   5 2.151000 0.2627118  19.37800 0.6121029
2   4    2   6 2.398000 0.7485412  18.93667 2.2924368
3   6    1   2 3.337500 0.1732412  19.83000 0.5515433
4   6    4   4 3.093750 0.4131460  17.67000 1.1249296
5   6    6   1 2.770000        NA  15.50000        NA
6   8    2   4 3.560000 0.1939502  17.06000 0.1783255
7   8    3   3 3.860000 0.1835756  17.66667 0.3055050
8   8    4   6 4.433167 1.0171431  16.49500 1.4424112
9   8    8   1 3.570000        NA  14.60000        NA
#+end_example

** Ggplot2
*** ggplot2: Modularity in Action
- =ggplot2= builds on plyr and on a modular *grammar of graphics*
- +obnoxious function with dozens of arguments+
- *combine* small functions using layers and transformations
- *aesthetic* mapping between *observation characteristics* (data frame column
  names) and *graphical* object *variables*
- an incredible *documentation*: http://docs.ggplot2.org/current/
  #+BEGIN_CENTER
  #+ATTR_LaTeX: :height 6cm
  [[./images/ggplot2_doc.png]]
  #+END_CENTER
*** ggplot2: Illustration (1)
\small
#+BEGIN_SRC R :results output graphics :file ./pdf_babel/mtcars_ggplot1.pdf :width 5.5 :height 4 :exports  both :session
ggplot(data = mtcars, aes(x=wt, y=qsec, color=cyl)) +  
       geom_point();
#+END_SRC

#+BEGIN_CENTER
#+ATTR_LaTeX: :height 6cm 
#+RESULTS:
[[file:./pdf_babel/mtcars_ggplot1.pdf]]
#+END_CENTER
*** ggplot2: Illustration (2)
\small
#+BEGIN_SRC R :results output graphics :file ./pdf_babel/mtcars_ggplot2.pdf :width 5.5 :height 4 :exports  both :session
ggplot(data = mtcars, aes(x=wt, y=qsec, color=factor(cyl))) +  
       geom_point();
#+END_SRC

#+BEGIN_CENTER
#+ATTR_LaTeX: :height 6cm 
#+RESULTS:
[[file:./pdf_babel/mtcars_ggplot2.pdf]]
#+END_CENTER
*** ggplot2: Illustration (3)
\small
#+BEGIN_SRC R :results output graphics :file ./pdf_babel/mtcars_ggplot3.pdf :width 5.5 :height 4 :exports  both :session
ggplot(data = mtcars, aes(x=wt, y=qsec, color=factor(cyl),
       shape = factor(gear))) +  geom_point() + theme_bw() +
       geom_smooth(method="lm");
#+END_SRC

#+BEGIN_CENTER
#+ATTR_LaTeX: :height 6cm 
#+RESULTS:
[[file:./pdf_babel/mtcars_ggplot3.pdf]]
#+END_CENTER
*** ggplot2: Illustration (4)
\small
#+BEGIN_SRC R :results output graphics :file ./pdf_babel/mtcars_ggplot4.pdf :width 6 :height 4 :exports  both :session
ggplot(data = mtcars, aes(x=wt, y=qsec, color=factor(cyl),
       shape = factor(gear))) + geom_point() + theme_bw() +
       geom_smooth(method="lm") + facet_wrap(~ cyl);
#+END_SRC

#+BEGIN_CENTER
#+ATTR_LaTeX: :height 6cm 
#+RESULTS:
[[file:./pdf_babel/mtcars_ggplot4.pdf]]
#+END_CENTER
*** ggplot2: Illustration (5)
\small
#+BEGIN_SRC R :results output graphics :file ./pdf_babel/mtcars_ggplot5.pdf :width 6 :height 4 :exports  both :session
ggplot(data = movies, aes(x=year,y=rating,group=factor(year))) + 
       geom_boxplot() + facet_wrap(~Romance) + theme_bw() +
       theme(axis.text.x = element_text(angle = 45, hjust = 1), 
             panel.margin = unit(2, "lines"));
#+END_SRC

#+BEGIN_CENTER
#+ATTR_LaTeX: :height 6cm 
#+RESULTS:
[[file:./pdf_babel/mtcars_ggplot5.pdf]]
#+END_CENTER
*** ggplot2: Illustration (6)
\small
# From [[http://www.cookbook-r.com/Graphs/Facets_(ggplot2)/#modifying-facet-label-text]]
#+begin_src R :results output :session :exports none
mf_labeller <- function(var, value){
    value <- as.character(value)
    if (var=="Action") { 
        value[value=="0"] <- "No action :("
        value[value=="1"]   <- "Action"
    }
    if (var=="Comedy") { 
        value[value=="0"] <- "Serious stuff!"
        value[value=="1"]   <- "Comedy :D"
    }
    return(value);
}
#+end_src

#+RESULTS:

#+BEGIN_SRC R :results output graphics :file ./pdf_babel/mtcars_ggplot6.pdf :width 6 :height 4 :exports  both :session
ggplot(movies, aes(x = rating)) + geom_histogram(binwidth = 0.5)+
       facet_grid(Action ~ Comedy, labeller=mf_labeller) + 
       theme_bw() + theme(panel.margin = unit(.5, "lines"));
#+END_SRC

#+BEGIN_CENTER
#+ATTR_LaTeX: :height 6cm 
#+RESULTS:
[[file:./pdf_babel/mtcars_ggplot6.pdf]]
#+END_CENTER
** Reshape and tydiR
*** "Messy" data
When using ggplot or plyr, your data may not in the right shape, in
which case you should *give a try to reshape/melt*

#+begin_src R :results output :session :exports both

#+end_src

#+RESULTS:

#+begin_src R :results output :session :exports both
messy <- data.frame(
  name = c("Wilbur", "Petunia", "Gregory"),
  a = c(67, 80, 64),
  b = c(56, 90, 50)
)
messy
#+end_src

#+RESULTS:
:      name  a  b
: 1  Wilbur 67 56
: 2 Petunia 80 90
: 3 Gregory 64 50

- =a= and =b= are two different types of drugs and the values correspond to
  heart rate
- ggplot faceting or coloring based on the drug type is a pain
- we need a way to make "wide" data longer
*** Reshape
#+begin_src R :results output :session :exports both
library(reshape)
cleaner = melt(messy,c("name"))
names(cleaner)=c("name","drug","heartrate")
cleaner
#+end_src

#+RESULTS:
:      name drug heartrate
: 1  Wilbur    a        67
: 2 Petunia    a        80
: 3 Gregory    a        64
: 4  Wilbur    b        56
: 5 Petunia    b        90
: 6 Gregory    b        50

*** Tidyr
Just like plyr, reshape is a little magical. tidyr is the new
generation (faster, more coherent). Again, the [[http://blog.rstudio.org/2014/07/22/introducing-tidyr/][/tutorial/]] is
great.

#+begin_src R :results output :session :exports both
library(tidyr)
library(dplyr)
messy %>% gather(drug, heartrate, -name)
#+end_src

#+RESULTS:
:      name drug heartrate
: 1  Wilbur    a        67
: 2 Petunia    a        80
: 3 Gregory    a        64
: 4  Wilbur    b        56
: 5 Petunia    b        90
: 6 Gregory    b        50

*Hint:* Avoid mixing old-generation with new-generation as it overrides
some function names and leads to weird behaviors
** Now let's play!
*** Summarizing information
You may like these *cheat sheets*: 
#+BEGIN_CENTER
https://www.rstudio.com/resources/cheatsheets/
#+END_CENTER

#+begin_src R :results output :session :exports both
df = read.csv("data/set1.csv",header=T)
# Alternatively: read.csv("https://raw.githubusercontent.com/
#            alegrand/SMPE/master/lectures/data/set1.csv")
head(df,n=2)
#+end_src

#+RESULTS:
:          A        B
: 1 7.256717 8.261171
: 2 3.813100 4.335301

Get the following summary using =plyr/reshape= or =dplyr/tydir=:
#+begin_src R :results output :session :exports results
dfgg = df %>% gather(Alternative, Time) 
dfsum = dfgg %>% 
       group_by(Alternative) %>%
       summarise(num = n(),
                 mean = mean(Time),
                 sd = sd(Time),
		       min = min(Time),
		       max = max(Time))
dfsum
#+end_src

#+RESULTS:
: Source: local data frame [2 x 6]
: 
:   Alternative num     mean       sd      min       max
: 1           A  40 4.903817 1.544423 2.400016  9.172525
: 2           B  40 5.783643 1.542987 3.539874 10.027147
*** Plot the data
#+begin_src R :results output graphics :file pdf_babel/set1_1.pdf :exports results :width 6 :height 4 :session
ggplot(data=dfgg,aes(x=Alternative,y=Time,color=Alternative)) +
    geom_point()
#+end_src

#+RESULTS:
[[file:pdf_babel/set1_1.pdf]]

*** Alleviate over-plotting
#+begin_src R :results output graphics :file pdf_babel/set1_2.pdf :exports results :width 6 :height 4 :session
ggplot(data=dfgg,aes(x=Alternative,y=Time,color=Alternative)) + 
    geom_point(alpha=.4) + theme_bw()
#+end_src

#+RESULTS:
[[file:pdf_babel/set1_2.pdf]]
*** Avoid over-plotting
#+begin_src R :results output graphics :file pdf_babel/set1_3.pdf :exports results :width 6 :height 4 :session
ggplot(data=dfgg,aes(x=Alternative,y=Time,color=Alternative)) + 
    geom_jitter(alpha=.4,position = position_jitter(width = .2)) + 
    theme_bw()
#+end_src

#+RESULTS:
[[file:pdf_babel/set1_3.pdf]]
*** Add summary information
#+begin_src R :results output graphics :file pdf_babel/set1_4.pdf :exports results :width 6 :height 4 :session
ggplot(data=dfgg,aes(x=Alternative,y=Time,color=Alternative)) + 
    geom_jitter(alpha=.4,position = position_jitter(width = .2)) + 
    geom_pointrange(data=dfsum,
                     aes(x=Alternative,y=mean,ymin=min,ymax=max)) +
    theme_bw()
#+end_src

#+RESULTS:
[[file:pdf_babel/set1_4.pdf]]
*** Add more standard summaries
#+begin_src R :results output graphics :file pdf_babel/set1_5.pdf :exports results :width 6 :height 4 :session
ggplot(data=dfgg,aes(x=Alternative,y=Time,color=Alternative)) + 
    geom_boxplot(width=.4) +
    geom_jitter(alpha=.4,position = position_jitter(width = .2)) + 
    theme_bw()
#+end_src

#+RESULTS:
[[file:pdf_babel/set1_5.pdf]]
*** Or depict confidence intervals
#+begin_src R :results output graphics :file pdf_babel/set1_8.pdf :exports results :width 6 :height 4 :session
dfgg %>% group_by(Alternative) %>% 
         summarize(num=n(), sd=sd(Time), se=sd/sqrt(num), Time=mean(Time)) %>%
    ggplot(aes(x=Alternative,y=Time)) + 
#        geom_boxplot(data=dfgg,color="gray") +
        geom_point(shape=21,size=3) + 
        geom_errorbar(aes(ymin=Time-2*se,ymax=Time+2*se), width=.1) + 
        ylim(0,NA) + ylab("Time (s) \n with 95% confidence intervals") +
        theme_bw()
#+end_src

#+RESULTS:
[[file:pdf_babel/set1_8.pdf]]
*** Or use histograms...
#+begin_src R :results output graphics :file pdf_babel/set1_6.pdf :exports results :width 6 :height 4 :session
ggplot(data=dfgg,aes(x=Time,fill=Alternative)) + 
    geom_histogram() + facet_wrap(~Alternative,ncol=1) +
    theme_bw()
#+end_src

#+RESULTS:
[[file:pdf_babel/set1_6.pdf]]
*** Be careful with fancy plots you do not fully understand!
#+begin_src R :results output graphics :file pdf_babel/set1_7.pdf :exports results :width 7 :height 4 :session
library(gridExtra)
p1 = ggplot(data=dfgg,aes(x=Time,fill=Alternative)) + 
     geom_histogram(aes(y = ..density..)) + 
     geom_density(alpha=.3) + facet_wrap(~Alternative,ncol=1) +
     theme_bw()
p2 = ggplot(data=dfgg,aes(x=Alternative,y=Time,fill=Alternative)) + 
     geom_jitter(alpha=.4,position = position_jitter(width = .2)) + 
     geom_dotplot(binaxis = "y", stackdir = "center") + 
     geom_violin(scale="area",trim=FALSE,alpha=.4) + theme_bw()
grid.arrange(p1,p2,nrow=1)
#+end_src

#+RESULTS:
[[file:pdf_babel/set1_7.pdf]]
** Conclusion
*** Take away Message
- R, ggplot and other such tools are *incredibly powerful for
  presenting data*. They are much more high level than any other tools
  I have seen so far.
- Mastering it *will save you a lot of time* as it will allow to look at
  your data through *different angles* and thus *check many hypothesis*
  and *present* them *in the best possible way*
- Read at least Jain's book: *The Art of Computer Systems Performance
  Analysis*
- However, you may have started understanding that a visualization is
  meant to check or to illustrate one particular aspect and that this
  "aspect" relies on a *mathematical model*. I will thus explain you in
  the next lecture what this model is.

\textbf{To do for the Next Time}: Use what you just learned to improve
your data analysis, the article you're currently writing, ...\medskip


* Descriptive statistics of an univariate sample
** Motivation
*** Motivation
We have set up a world where we keep collecting data, *huge amount of
data*...

Sweet, what knowledge can we exctract from such data? How do we
summarize a data set? 

With a few numbers, some graphics? How? Why is this difficult? \medskip

**** 
#+BEGIN_QUOTE
There are three kinds of lies: lies, damned lies and statistics\vspace{-1.5em}
#+END_QUOTE
#+LaTeX: \begin{flushright}
-- Mark Twain’s Autobiography
# The Chapters from the North American Review
#+LaTeX: \end{flushright}

#+BEGIN_QUOTE
Statistical thinking will one day be as necessary for efficient
citizenship as the ability to read or write\vspace{-1.5em}
#+END_QUOTE
#+LaTeX: \begin{flushright}
    -- Attributed to H. G. Wells 
#+LaTeX: \end{flushright}

#+BEGIN_QUOTE
The only statistics you can trust are those you falsified yourself\vspace{-1.5em}
#+END_QUOTE
#+LaTeX: \begin{flushright}
    -- Winston Churchill
#+LaTeX: \end{flushright}

** Initial step
*** I just got new Tees!
- A series of *measurements* (one value per measurement)
- *Nature* of the measurements
  - Factors (*nominal data*)
    #+begin_src R :results output :session :exports results
    set.seed(42);
    options(width=58);
    T_color = sample(size=20, 
        factor(c("Black","Red","Blue","White","Green")), 
        prob=c(.6,.1,.1,.1,.1),replace=T);
    T_color
    #+end_src

    #+RESULTS:
    :  [1] Red   Red   Black Green Blue  Black White Black Blue 
    : [10] White Black White Red   Black Black Red   Red   Black
    : [19] Black Black
    : Levels: Black Blue Green Red White

  - Ordered factors (*ordinal data*)
    #+begin_src R :results output :session :exports results
    options(width=55);
    sizes = c("S","M","L","XL");
    sizes = factor(sizes, levels=sizes, ordered=T)
    T_size = sample(size=20, sizes,
                    prob=c(.05,.75,.1,.05),replace=T);
    T_size
    #+end_src

    #+RESULTS:
    :  [1] XL M  S  XL M  M  M  XL M  L  M  L  M  M  M  L  M 
    : [18] M  XL M 
    : Levels: S < M < L < XL

  - Numbers (e.g., price, duration, \dots) (*numerical data*)
    #+begin_src R :results output :session :exports results
    options(width=58);
    T_price = round(10+rnorm(20,sd=3),digit=1);
    T_price
    #+end_src

    #+RESULTS:
    :  [1]  9.1  4.7  9.5 13.6 15.7  8.7  9.2  4.7 11.4  8.1
    : [11] 11.4 12.1 13.1  8.2 11.5  4.8  7.6  7.4  2.8 10.1

#+begin_src R :results output :session :exports both
str(T_size); # May want to use the str function
#+end_src

#+RESULTS:
:  Ord.factor w/ 4 levels "S"<"M"<"L"<"XL": 4 2 1 4 2 2 2 4 2 3 ...

*** Are these sample "structured"?
#+LaTeX: \begin{columns}\begin{column}{.5\linewidth}
Use =plot.ts= (for *time series*)

#+begin_src R :results output graphics :file pdf_babel/ds_ts1.pdf :exports both :width 4 :height 6 :session
par(mfrow=c(3,1));
plot.ts(T_color,xy.lines=F);
plot.ts(T_size,xy.lines=F);
plot.ts(T_price,xy.lines=F);
#+end_src
#+LaTeX: \end{column}\begin{column}{.5\linewidth}
#+RESULTS:
[[file:pdf_babel/ds_ts1.pdf]]
#+LaTeX: \end{column}\end{columns}
*** Are these sample "structured"?
Fancier output can be built using =ggplot2=
#+begin_src R :results output graphics :file pdf_babel/ds_ts2.pdf :exports results :width 5 :height 5 :session
library(ggplot2)
library(gridExtra)
p1 = ggplot(data.frame(Time=1:length(T_color),Color=T_color),
            aes(x=Time,y=Color,fill=Color)) +
     geom_point(shape=21)  + theme_bw() + 
     scale_fill_manual(values = tolower(as.character(levels(T_color))))
p2 = ggplot(data.frame(Time=1:length(T_size),Size=T_size),aes(x=Time,y=Size,size=Size)) +
     geom_point() + theme_bw();
p3 = ggplot(data.frame(Time=1:length(T_price),Price=T_price),aes(x=Time,y=Price)) +
     geom_line(color="gray") + geom_point() + theme_bw();
grid.arrange(p1,p2,p3,ncol=1);
#+end_src

#+BEGIN_CENTER
  #+ATTR_LaTeX: :width .6\linewidth
  #+RESULTS:
  [[file:pdf_babel/ds_ts2.pdf]]
#+END_CENTER
*** There could indeed be "trends"
#+begin_src R :results output :session :exports none
set.seed(42);
N=100;
T_price_time = 1:N;
T_price_trend = round(10+.07*T_price_time + rnorm(20,sd=3) + rnorm(N,sd=.5),digit=1);
T_price_trend2 = atan(T_price_time/10)+.2*rnorm(N);
T_price_trend2[60:64] = 0;
T_price_trend3 = 2+sin(T_price_time/5)*(1+rnorm(N))+.2*rnorm(N);
T_price_trend4 = 5+atan(T_price_time-N/2)+runif(N);
T_price_trend4[30] = 12
#+end_src

#+RESULTS:

#+begin_src R :results output graphics :file pdf_babel/ds_ts3.pdf :exports results :width 8 :height 6 :session
par(mfrow=c(2,2));
plot.ts(T_price_trend);
plot.ts(T_price_trend2);
plot.ts(T_price_trend3);
plot.ts(T_price_trend4);
par(mfrow=c(1,1));
#+end_src

#+RESULTS:
[[file:pdf_babel/ds_ts3.pdf]]
*** What should we look for?
- Structured/unstructured
- Trend, evolution
- Localization/order of magnitude
- Outliers, aberrant values

This preliminary study will:
- guide your analysis
- provide feedback on your experimental setup\smallskip

This may be harder to do than it looks...

#+begin_src R :results output graphics :file pdf_babel/ds_ts4.pdf :exports results :width 8 :height 3 :session
ggplot(data.frame(Time=1:5000,Price=rnorm(5000)),aes(x=Time,y=Price)) +
     geom_line(color="gray") + geom_point() + theme_bw();
#+end_src

#+RESULTS:
[[file:pdf_babel/ds_ts4.pdf]]

** Histograms of "Stable" samples
*** Bar charts vs. Histograms
#+LaTeX: \begin{columns}\begin{column}{.5\linewidth}
#+begin_src R :results output graphics :file pdf_babel/ds_bar1.pdf :exports both :width 4 :height 6 :session
par(mfrow=c(3,1));
plot(T_color,xy.lines=F);
plot(T_size,xy.lines=F);
hist(T_price,xy.lines=F);
#+end_src
#+LaTeX: \end{column}\begin{column}{.5\linewidth}
#+RESULTS:
[[file:pdf_babel/ds_bar1.pdf]]
#+LaTeX: \end{column}\end{columns}
*** Bar charts vs. Histograms
Again, fancier output can be built using =ggplot2=
#+begin_src R :results output graphics :file pdf_babel/ds_bar2.pdf :exports results :width 5 :height 5 :session
library(ggplot2)
library(gridExtra)
p1 = ggplot(data.frame(Time=1:length(T_color),Color=T_color),
            aes(x=Color,fill=Color)) + 
     geom_bar(color="black")  + 
     scale_fill_manual(values = tolower(as.character(levels(T_color))))
p2 = ggplot(data.frame(Time=1:length(T_size),Size=T_size),
            aes(x=Size)) +
     geom_bar(fill="gray",color="black") + theme_bw();
p3 = ggplot(data.frame(Time=1:length(T_price),Price=T_price),
            aes(x=Price)) +
     geom_histogram(fill="gray",color="black") + theme_bw();
grid.arrange(p1,p2,p3,ncol=1);
#+end_src

#+BEGIN_CENTER
  #+ATTR_LaTeX: :width .6\linewidth
  #+RESULTS:
  [[file:pdf_babel/ds_bar2.pdf]]
#+END_CENTER
*** Wait, why are these histograms so different?
#+begin_src R :results output graphics :file pdf_babel/ds_bar3_1.pdf :exports none :width 5 :height 3.5 :session
hist(T_price,xy.lines=F);
#+end_src

#+RESULTS:
[[file:pdf_babel/ds_bar3_1.pdf]]

#+begin_src R :results output graphics :file pdf_babel/ds_bar3_2.pdf :exports none :width 5 :height 3.5 :session
hist(T_price,xy.lines=F,probability=T);
#+end_src

#+RESULTS:
[[file:pdf_babel/ds_bar3_2.pdf]]

#+begin_src R :results output graphics :file pdf_babel/ds_bar3_3.pdf :exports none :width 5 :height 2.3 :session
ggplot(data.frame(Time=1:length(T_price),Price=T_price),
            aes(x=Price)) +
     geom_histogram(fill="gray",color="black") + theme_bw();
#+end_src

#+RESULTS:
[[file:pdf_babel/ds_bar3_3.pdf]]

#+begin_src R :results output graphics :file pdf_babel/ds_bar3_4.pdf :exports none :width 5 :height 2.3 :session
ggplot(data.frame(Time=1:length(T_price),Price=T_price),
            aes(x=Price, y=..density..)) +
     geom_histogram(fill="gray",color="black") + theme_bw();
#+end_src

#+RESULTS:
[[file:pdf_babel/ds_bar3_4.pdf]]

#+begin_src R :results output graphics :file pdf_babel/ds_bar3_5.pdf :exports none :width 5 :height 2.3 :session
ggplot(data.frame(Time=1:length(T_price),Price=T_price),
            aes(x=Price, y=..density..)) +
     geom_histogram(fill="gray",color="black",binwidth=2) + theme_bw();
#+end_src

#+RESULTS:
[[file:pdf_babel/ds_bar3_5.pdf]]

#+LaTeX: \begin{columns}\begin{column}{.5\linewidth}
  #+ATTR_LaTeX: :width \linewidth
  [[file:pdf_babel/ds_bar3_1.pdf]]

  #+ATTR_LaTeX: :width \linewidth
  [[file:pdf_babel/ds_bar3_2.pdf]]
#+LaTeX: \end{column}\begin{column}{.5\linewidth}
  #+ATTR_LaTeX: :width \linewidth
  [[file:pdf_babel/ds_bar3_3.pdf]]

  #+ATTR_LaTeX: :width \linewidth
  [[file:pdf_babel/ds_bar3_4.pdf]]

  #+ATTR_LaTeX: :width \linewidth
  [[file:pdf_babel/ds_bar3_5.pdf]]
#+LaTeX: \end{column}\end{columns}
*** Beware of histograms
#+BEGIN_CENTER
  \textbf{Rather indicate density than count} \medskip
#+END_CENTER

*How many bins? Which binwidth?*
- =ggplot= defaults to $k=30$ bins of width $h$ = =range/30= \frowny
- Square-root choice: $k = \sqrt{n}$ (Excel, \frowny)
- Sturges: $k = \lceil \log_2 n + 1 \rceil$ (default for =hist= in R)
- Rice: $k = \lceil 2 n^{1/3}\rceil$
- Scott: $k = \left \lceil \frac{\max x - \min x}{h}
  \right \rceil$, where: $h = \frac{3.5 \hat \sigma}{n^{1/3}}$ (equivalent to Rice
  under some conditions)
- ...
*** Beware of Histograms
*At which value should the bin start?*
- In most cases, the binning is aligned on human readable values,
  which can create nasty artifacts (nice illustration from
  [[http://stats.stackexchange.com/questions/51718/assessing-approximate-distribution-of-data-based-on-a-histogram/][/stackexchange/]])
#+begin_src R :results output graphics :file pdf_babel/ds_bar4.pdf :exports results :width 7 :height 4 :session
A <- c(3.15,5.46,3.28,4.2,1.98,2.28,3.12,4.1,3.42,3.91,2.06,5.53,
       5.19,2.39,1.88,3.43,5.51,2.54,3.64,4.33,4.85,5.56,1.89,4.84,
       5.74,3.22, 5.52,1.84,4.31,2.01,4.01,5.31,2.56,5.11,2.58,4.43,
       4.96,1.9,5.6,1.92);

df = rbind(data.frame(val=A,set="A"),
           data.frame(val=A-.25,set="B"),
           data.frame(val=A-.5, set="C"),
           data.frame(val=A-.75,set="D"));
df$y = runif(length(A),min=3,max=6);

p1 = ggplot(df,aes(x=val)) + theme_bw() + xlab("Values") +
     facet_wrap(~set,ncol=2) + 
     geom_histogram(binwidth=1,fill="gray",color="black") + 
     geom_point(data=df,aes(x=val,y=y),shape=21,size=2,fill="white",alpha=.5);
# p2 = ggplot(df,aes(y=factor(set, levels = rev(levels(set))),x=val)) + theme_bw() +
#        geom_vline(xintercept=1:6, colour="green", linetype = "longdash") +
#        geom_point(shape=21,size=3) + xlim(0,7) + ylab("Set") + xlab("Values");


x <- c(1.03, 1.24, 1.47, 1.52, 1.92, 1.93, 1.94, 1.95, 1.96, 1.97, 1.98, 
  1.99, 2.72, 2.75, 2.78, 2.81, 2.84, 2.87, 2.9, 2.93, 2.96, 2.99, 3.6, 
  3.64, 3.66, 3.72, 3.77, 3.88, 3.91, 4.14, 4.54, 4.77, 4.81, 5.62)
# p3_1 = ggplot(data.frame(val=x),aes(x=val)) + theme_bw() + xlab("Values") + xlim(0,6) +
#        geom_histogram(binwidth=1,fill="gray",color="black") + 
#        geom_point(y=2.5,shape=21,size=3);
# p3_2 = ggplot(data.frame(val=x),aes(x=val)) + theme_bw() + xlab("Values") + xlim(0,6) +
#        geom_histogram(binwidth=.8,origin=.3,fill="gray",color="black") + 
#        geom_point(y=2.5,shape=21,size=3);

df = rbind(data.frame(val=x,set="E",binwidth=1,origin=1),
           data.frame(val=x,set="E ",binwidth=.8,origin=.3));
df$y= runif(length(x),min=3,max=6);
p3 = ggplot(df,aes(x=val)) + 
       theme_bw() + xlab("Values") + xlim(0,6) +
       facet_wrap(~set,ncol=1) + 
       geom_histogram(data=df[df$binwidth==1,],binwidth=1,origin=1,fill="gray",color="black") + 
       geom_histogram(data=df[df$binwidth==.8,],binwidth=.8,origin=.3,fill="gray",color="black") +
       geom_point(aes(y=y),shape=21,fill="white",size=3,alpha=.5) +
       geom_vline(xintercept=1:6, colour="green", linetype = "longdash");

grid.arrange(p1,p3,nrow=1,widths=c(1.5,1));
# grid.arrange(p1,p2,nrow=1);
# grid.arrange(p3_1,p3_2,ncol=1);
#+end_src

#+BEGIN_CENTER
  #+ATTR_LaTeX: :width \linewidth
  #+RESULTS:
  [[file:pdf_babel/ds_bar4.pdf]]
#+END_CENTER

*** What should we look for?
*Shape*: flat? symmetrical? multi-modal? Play with =binwidth= (and
=origin= if you have few samples) to uncover the full story behind your
data...

#+begin_src R :results output graphics :file pdf_babel/ds_bar5.pdf :exports results :width 7 :height 4 :session
library(ggplot2)
library(gridExtra)
p1 = ggplot(data.frame(x=rnorm(1000,mean=5,sd=2)),
            aes(x=x, y=..density..)) + theme_bw() +
     geom_histogram(color="black",fill="gray",binwidth=1) 
p2 = ggplot(data.frame(x=runif(1000,min=2,max=40)),
            aes(x=x, y=..density..)) + theme_bw() +
     geom_histogram(color="black",fill="gray",binwidth=5) 

x = rbinom(1000,size=1,prob=.3)
x = 4*x + rnorm(1000)
p3 = ggplot(data.frame(x=x),
            aes(x=x, y=..density..)) + theme_bw() +
     geom_histogram(color="black",fill="gray",binwidth=1) 

x = rbinom(1000,size=1,prob=.3)
x = 4*x + rexp(1000) + .1*rnorm(1000)
p4 = ggplot(data.frame(x=x),
            aes(x=x, y=..density..)) + theme_bw() +
     geom_histogram(color="black",fill="gray",binwidth=1) 

p5 = ggplot(data.frame(x=rgamma(1000,shape=.2)),
            aes(x=x, y=..density..)) + theme_bw() +
     geom_histogram(color="black",fill="gray",binwidth=.5) 

p6 = ggplot(data.frame(x=rlnorm(1000)),
            aes(x=x, y=..density..)) + theme_bw() +
     geom_histogram(color="black",fill="gray",binwidth=1) 

grid.arrange(p1,p2,p3,p4,p5,p6,nrow=2);
#+end_src

#+BEGIN_CENTER
  #+ATTR_LaTeX: :width \linewidth
  #+RESULTS:
  [[file:pdf_babel/ds_bar5.pdf]]
#+END_CENTER

** Single mode: central tendency
*** Nominal Values
#+LaTeX: \begin{columns}\begin{column}{.6\linewidth}
- What is the *mode* (most frequent value)?
- Sort values according to their frequency...
  #+begin_src R :results output :session :exports both
  summary(T_color)
  #+end_src

  #+RESULTS:
  : Black  Blue Green   Red White 
  :    11     1     1     2     5

#+LaTeX: \end{column}\begin{column}{.4\linewidth}
  [[file:pdf_babel/ct_bar1.pdf]]

#+LaTeX: \end{column}\end{columns}\bigskip

\small
#+begin_src R :results output graphics :file pdf_babel/ct_bar1.pdf :exports code :width 4.5 :height 4 :session
col_freq=table(T_color);
T_color <- factor(T_color,
    levels = names(col_freq[order(col_freq, decreasing = TRUE)]));
plot(T_color);
#+end_src

#+RESULTS:
[[file:pdf_babel/ct_bar1.pdf]]

*** Ordinal Values
#+LaTeX: \begin{columns}\begin{column}{.5\linewidth}
- What is the *mode* (most frequent value)?
  #+begin_src R :results output :session :exports both
  summary(T_size)
  #+end_src

  #+RESULTS:
  :  S  M  L XL 
  :  1 17  1  1
- May still want to sort values according to their frequency...
- *Median*: not implemented in standard R for ordinal values, as it's
  not well defined

#+LaTeX: \end{column}\begin{column}{.5\linewidth}
  [[file:pdf_babel/ct_bar2.pdf]]

#+LaTeX: \end{column}\end{columns}

\small

#+begin_src R :results output :session :exports both
median(T_size)
library(DescTools)
median(T_size) # :(
#+end_src

#+RESULTS:
: Error in median.default(T_size) : requires numerical data
: [1] NA

#+begin_src R :results output graphics :file pdf_babel/ct_bar2.pdf :exports none :width 4.5 :height 4 :session
plot(T_size);
#+end_src

#+RESULTS:
[[file:pdf_babel/ct_bar2.pdf]]
*** Numerical Values
#+begin_src R :results output :session :exports both
str(T_price);
#+end_src

#+RESULTS:
:  num [1:20] 14.5 13.1 9.3 6.9 8.6 7.2 7.3 12.4 13.1 16 ...

#+begin_src R :results output :session :exports both
summary(T_price);
#+end_src

#+RESULTS:
:    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
:   5.200   7.275   9.500   9.960  12.580  16.000

- =min=, =max=, =median= in R
- Median: 50% of values are smaller than 9.5\\\quad (a possible measure of *central tendency*)

*** Numerical Values
The *mode* and the *median* are measures of *central tendency* (typical
value)
- *Note*: There may be several modes and it depends on binning...

There is also the (arithmetic) *mean*: $A = \overline{x} = \frac{1}{N}\sum_{i=1}^N x_i$
#+begin_src R :results output :session :exports both
mean(T_price)
#+end_src

#+RESULTS:
: [1] 9.96

#+begin_src R :results output graphics :file pdf_babel/ct_hist.pdf :exports results :width 6 :height 3 :session
df = data.frame(x=rgamma(1000,shape=2));
bw = .5;

bks = hist(df$x,plot=F,breaks=ceiling(diff(range(df$x))/bw));
ibks = bks$counts==max(bks$counts)
Mode = mean(c(bks$breaks[c(ibks,F)], bks$breaks[c(F,ibks)]));

ct = rbind(data.frame(x=median(df$x), label="Median", y=.3),
           data.frame(x=mean(df$x), label="Mean", y=.2),
           data.frame(x=Mode, label="Mode", y=.4));

ggplot(df, aes(x=x, y=..density..)) + theme_bw() +
     geom_histogram(alpha=.3,color="black", fill="gray", binwidth=bw)  +
     geom_vline(data=ct, aes(xintercept=x,color=label),linetype = "longdash") +
     geom_text(data=ct, aes(x=x+.2,y=y,label=label,color=label),hjust=0) +
     scale_color_brewer(palette="Set1");
#+end_src

#+RESULTS:
[[file:pdf_babel/ct_hist.pdf]]

*** Things to know about the mean
- This measure is sensitive to "*outliers*".
  - One aberrant (say very large) value will drag the mean to the
    right while it would not change the median
- The key question is *what makes sense*?
  + Your favorite pair has been added a +20% mark-up in August but you
    have a -20% discount as a regular customer. Is the price the same?
    + No, you actually saved 4% of the original price ($1.2\times.8 = .96$).
  + You drove half the way at 50mph and half of the way at 100mph. Did
    you drive on average at 75mph?
    + Obviously not...
  + Although you can compute the average of gains/loss, it is not at
    all what you would consider as the average gain.
  + May want to consider the geometric or the harmonic mean...  $$G =
    \sqrt[n]{\prod_{i=1}^N x_i} \text{ or } H = \frac{1}{\frac{1}{N}\sum_{i=1}^N
    \frac{1}{x_i}}$$
*** What should I look for?
- If the distribution is unimodal and symmetrical, then 
  #+BEGIN_CENTER
  mean =  mode = median\bigskip
  #+END_CENTER
- Depending on the problem, one or the other may be more
  relevant\bigskip
- Anyway, reporting such measure with no indication about variability
  is generally useless
** Dispersion: Variability around the central tendency
*** Variance
We expect most values to be "around" the mean

#+begin_src R :results output graphics :file pdf_babel/var_1.pdf :exports results :width 7 :height 3 :session
N = 1000;
df = rbind(data.frame(x=rnorm(N,mean=3,sd=1), set="A"),
           data.frame(x=rnorm(N,mean=3,sd=.1), set="B"),
           data.frame(x=rnorm(N,mean=3,sd=3), set="C"));
ggplot(df,aes(x=x,y=..density..)) + geom_histogram(color="black", fill="gray") + 
       facet_wrap(~set) + 
       geom_vline(xintercept=3,color="red",linetype = "longdash");
#+end_src

#+BEGIN_CENTER
  #+ATTR_LaTeX: :width .8\linewidth
  #+RESULTS:
  [[file:pdf_babel/var_1.pdf]]
#+END_CENTER

Departure from the mean:
- Mean absolute deviation: $\frac{1}{N} \sum_{i=1}^N |x_i-A|$
  - Rarely used
- *Variance*: $V = \frac{1}{N} \sum_{i=1}^N (x_i-A)^2$
  - only positive values and gives more importance to large
    deviations \smiley
  - not homogeneous to the mean (units) \frowny
- *Standard deviation*: $SD = \sqrt{V}$
*** Quantile
#+begin_src R :results output :session :exports both
quantile(T_price,c(.05,.25,.5,.75,.95))
#+end_src

#+RESULTS:
:     5%    25%    50%    75%    95% 
:  4.605  7.550  9.150 11.425 13.705

Inter-Quantile Range:
- *Inter-quartile range*: $IQR = Q_{75}-Q_{25}$
- But other values are possible, e.g., $Q_{95}-Q_{5}$
- *Range*: $\max - \min$ (may grow unbounded)
  - $\leadsto$ quite difficult to use
*** What about nominal or ordinal values?
There is for example the notion of *Entropy*: how many bits are required
to encode the sample?

Say there is a fraction $f_v$ of items with value $v$.

$$H = - \sum_{v\in V} f_v\log_2(f_v)$$

$-(x+y)\log_2(x+y)<-x\log_2(x)-y\log_2(y)$ so *the smaller the
entropy, the more condensed/predictable the sample distribution*
- $H([0,1,0,0])=0$
- $H([.25,.25,.25,.25])=2$
- $H([1/n, \dots, 1/n])=\log_2(n)$ so you generally normalize $H$ by
  $\log_2(n)$ \medskip

This notion can be *extended to numerical values* (but the computation
is complex as it depends on the binning...)

** Going further
*** Skewness
Remember the *mean* and the *variance*: 
- $A = \overline{x} = \frac{1}{N} \sum_{i=1}^N x_i$
- $V = \frac{1}{N} \sum_{i=1}^N (x_i-\overline{x})^2$

Could we measure the asymmetry of the samples around the mean?

- Proposal 1: $\frac{1}{N} \sum_{i=1}^N (x_i-\overline{x})$ \hfill (always 0... \frowny)
- Proposal 2: $\frac{1}{N} \sum_{i=1}^N (x_i-\overline{x})^3$ \hfill (not
  well normalized... \frowny)

$$S = \frac{\displaystyle\frac{1}{n} \sum_{i=1}^n
(x_i-\overline{x})^3}{\Bigg[\underbrace{\frac{1}{n} \sum_{i=1}^n
(x_i-\overline{x})^2}_{\text{variance}}\Bigg]^{3/2}}$$
*** Skewness
Could we illustrate this a bit? 
#+begin_src R :results output :session :exports both
library(moments)
skewness(runif(1000))
#+end_src

#+RESULTS:
: [1] 0.04626483

#+begin_src R :results output graphics :file pdf_babel/var_2.pdf :exports results :width 6 :height 4 :session
df_skew = function (x) {
  s=skewness(x);
  l=paste("Skewness = ",round(s,digits=3));
  data.frame(x=x,label=l);
}

df = rbind(df_skew(runif(1000,min=-3,max=3)),
           df_skew(rnorm(1000)),
           df_skew(rgamma(1000,shape=3)),
           df_skew(10-rgamma(1000,shape=3)));

ggplot(df,aes(x=x,y=..density..)) + theme_bw() +
    geom_histogram(fill="gray",color="black") + facet_wrap(~label);
#+end_src

#+BEGIN_CENTER
  #+ATTR_LaTeX: :width .8\linewidth
  #+RESULTS:
  [[file:pdf_babel/var_2.pdf]]
#+END_CENTER
*** Kurtosis
- peakedness (width of peak), tail weight, lack of shoulders...
- measure infrequent extreme deviations, as opposed to frequent
  modestly sized deviations

$$K = \frac{\tfrac{1}{n} \sum_{i=1}^n (x_i -
\overline{x})^4}{\Bigg[\underbrace{\tfrac{1}{n} \sum_{i=1}^n (x_i -
\overline{x})^2}_{\text{variance}}\Bigg]^2} - 3$$

The *-3* is here so that normal distribution have a Kurtosis of 0

#+begin_src R :results output :session :exports both
library(moments)
x = rnorm(1000) ; var(x);
kurtosis(x)-3
#+end_src

#+RESULTS:
: [1] 1.039743
: [1] 0.01825114

*** Kurtosis

#+begin_src R :results output graphics :file pdf_babel/var_3.pdf :exports results :width 6 :height 4 :session
df_kurtosis = function (x) {
  s=kurtosis(x)-3;
  l=paste("Kurtosis = ",round(s,digits=3));
  data.frame(x=x,label=l);
}

n=1000
df = rbind(df_kurtosis(runif(n,min=0,max=5)),
           df_kurtosis(rnorm(n)),
           df_kurtosis((2*floor(runif(n,min=0,max=2))-1)*rgamma(n,shape=5)),
           df_kurtosis((2*floor(runif(n,min=0,max=2))-1)*rgamma(n,shape=.4)));

ggplot(df,aes(x=x,y=..density..)) + theme_bw() +
    geom_histogram(fill="gray",color="black") + facet_wrap(~label);
#+end_src

#+BEGIN_CENTER
  #+ATTR_LaTeX: :width \linewidth
  #+RESULTS:
  [[file:pdf_babel/var_3.pdf]]
#+END_CENTER

** Summarizing a distribution
*** Classical information
#+begin_src R :results output :session :exports none
x = rgamma(100,shape=3)
dfx=data.frame(val=x);
#+end_src

#+RESULTS:

#+begin_src R :results output graphics :file pdf_babel/summary_1.pdf :exports results :width 6 :height 3 :session
gghist = function(x) {
  breaks=ceiling(log2(length(x)+1));
  bw = diff(range(x))/breaks;
  ggplot(data.frame(x=x),aes(x=x,y=..density..)) + theme_bw() +
      geom_histogram(fill="gray",color="black",binwidth=bw);
}
gghist(x);
#+end_src

#+RESULTS:
[[file:pdf_babel/summary_1.pdf]]

#+begin_src R :results output :session :exports both
summary(x)
var(x)
#+end_src

#+RESULTS:
:    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
:  0.4065  1.8430  2.5020  2.8660  3.6310  7.0220
: [1] 2.117541
*** Good and bad summaries

#+begin_src R :results output graphics :file pdf_babel/summary_2.pdf :exports results :width 6 :height 4 :session
dfx=rbind(data.frame(val=x,label="min/max"),
          data.frame(val=x,label="+/- sd"),
          data.frame(val=x,label="boxplot"),
          data.frame(val=x,label="confidence\ninterval"))

dfx$label = factor(dfx$label, 
    levels = c("min/max", "+/- sd", "boxplot", "confidence\ninterval"));

ggplot(data=dfx,aes(y=val, x=as.factor(label))) + theme_bw() + xlab("Method") + 
    geom_boxplot(data=dfx[dfx$label=="boxplot",],width =.3, color="dark green") + 
    geom_jitter(data=dfx,alpha=.2,position = position_jitter(width = .1)) +
    stat_summary(data=dfx[dfx$label=="boxplot",], fun.y="mean", geom = "point", shape=8, , color="dark green") +
    geom_pointrange(aes(x="min/max",y=mean(dfx$val),
                    ymin=min(dfx$val),ymax=max(dfx$val)), color="dark red") +
    geom_pointrange(aes(x="+/- sd",y=mean(dfx$val),
                    ymin=mean(dfx$val)-sd(dfx$val),ymax=mean(dfx$val)+sd(dfx$val)), color="dark red") +
    stat_summary(data=dfx[dfx$label=="confidence\ninterval",], fun.data="mean_cl_normal", geom = "errorbar", width=.1, , color="dark green") +
    stat_summary(data=dfx[dfx$label=="confidence\ninterval",], fun.y="mean", geom = "point", shape=21, , color="dark green")

#+end_src

#+BEGIN_CENTER
  #+ATTR_LaTeX: :width \linewidth
  #+RESULTS:
  [[file:pdf_babel/summary_2.pdf]]
#+END_CENTER

*** Be careful with fancy plots you do not fully understand!

#+BEGIN_EXPORT latex
\begin{center}
  \includegraphics<+>[height=6cm]{pdf_babel/set1_7.pdf}
  \includegraphics<+>[height=5cm]{pdf_babel/dist_summary1.pdf}
  \includegraphics<+>[height=5cm]{pdf_babel/dist_summary2.pdf}
\end{center}
#+END_EXPORT

**** 
#+BEGIN_QUOTE
The average human has one breast and one testicle\vspace{-1.5em}
#+END_QUOTE
#+LaTeX: \begin{flushright}
    -- Des McHale
#+LaTeX: \end{flushright}


