#+TITLE:     Reproducible Research for Computer Scientists
#+AUTHOR:    Arnaud Legrand
#+DATE: Performance Evaluation Lecture
#+STARTUP: beamer overview indent
#+TAGS: noexport(n)
#+LaTeX_CLASS: beamer
#+LaTeX_CLASS_OPTIONS: [11pt,xcolor=dvipsnames,presentation]
#+OPTIONS:   H:3 num:t toc:nil \n:nil @:t ::t |:t ^:nil -:t f:t *:t <:t
#+LATEX_HEADER: \input{org-babel-style-preembule.tex}
#+LATEX_HEADER: %\let\tmptableofcontents=\tableofcontents
#+LATEX_HEADER: %\def\tableofcontents{}
*** List                                                           :noexport:
- broken links (at least when reading .org from GitHub directly) on
  slides 44, 45, 69
*** Course Organization
#+BEGIN_CENTER
\bf *Scientific Methodology and Performance Evaluation\\
for Computer Scientists*
#+END_CENTER
- 5 lectures of 3 hours ::
     #+LaTeX: ~
  1. Reproducible research
  2. Data visualization/presentation
  3. Introduction to probabilities/statistics
  4. Linear regression
  5. Design of Experiments
- Stuff to know about this course ::
     #+LaTeX: ~
  - Way too much stuff for so little time. The slides are extremely
    dense and I speak very fast. *Don't panic*! Feel free to interrupt
  - Slides are self-content with many [[https://github.com/alegrand/M2R-ParallelQuicksort][/links/]] and =code=  examples
  - Try to *put into practice asap to get the most out of it* and *do not
    worry about the grade*
** 
#+LaTeX: \input{org-babel-document-preembule.tex}
#+LaTeX: %\let\tableofcontents=\tmptableofcontents
#+LaTeX: %\tableofcontents
* A Few Motivating Examples 
*** Naicken computation                                          :noexport:
#+tblname: naicken
| Type        | Count |
|-------------+-------|
| None        |   146 |
| Unspecified |    71 |
| Custom      |    43 |
| NS-2        |     8 |
| Chord-(SFS) |     7 |
| Javasim     |     2 |
| Peersim     |     2 |
| Aurora      |     1 |
| CSIM-19     |     1 |
| Modelnet    |     1 |
| Nab         |     1 |
| Narses      |     1 |
| Neurogrid   |     1 |
| P2PSim      |     1 |
| SOSS        |     1 |

#+begin_src R :results output graphics  :var df=naicken :file images/naicken.pdf :exports both :width 4 :height 4 :session
  library(ggplot2)
  df <- df[df$Type!="None",]
  df[!(df$Type %in% c("Unspecified","Custom","NS-2","Chord-(SFS)")),]$Type = "Other"
  df$Ratio = 100*df$Count / sum(df$Count)
  pie <- ggplot(df, aes(x = "", y = Ratio, fill = Type)) + 
         geom_bar(width = 1,  stat = "identity") + coord_polar(theta = "y") 
  pie + scale_fill_brewer(palette="Set1") + theme_bw() + ylab("") + xlab("") + 
        ggtitle("Simulator usage [Naicken06]")
#+end_src

#+RESULTS:
[[file:images/naicken.pdf]]

#+begin_src sh :results output :exports both
  pdfcrop images/naicken.pdf images/naicken.pdf
#+end_src

#+RESULTS:
: PDFCROP 1.38, 2012/11/02 - Copyright (c) 2002-2012 by Heiko Oberdiek.
: ==> 1 page written on `images/naicken.pdf'.
*** Frustration as an Author
- I thought I used the same parameters but *I'm getting different
  results!*
- The new student wants to compare with *the method I proposed last
  year*
- My advisor asked me whether I took care of setting this or this but
  I can't remember
- The damned fourth reviewer asked for a major revision and wants me
  to *change figure 3* :(
- *Which code* and *which data set* did I use to generate this figure?
- It *worked yesterday*!
- 6 months later: *why* did I do that?
*** Frustration as a Reviewer
This may be an interesting contribution but:
- This *average value* must hide something
- As usual, there is no *confidence interval*, I wonder about the
  variability and whether the difference is *significant* or not
- That can't be true, I'm sure they *removed some points*
- Why is this graph in *logscale*? How would it look like otherwise?
- The authors decided to show only a *subset of the data*. I wonder
  what the rest looks like
- There is no label/legend/... What is the *meaning of this graph*?
  If only I could access the generation script
*** A Few Edifying Examples
#+BEGIN_LaTeX
  \begin{columns}
    \begin{column}{.67\linewidth}
      \bottomcite{Naicken, Stephen \textit{et Al.}, \textit{Towards Yet
          Another Peer-to-Peer Simulator}, HET-NETs'06.}\medskip\\
      \small
      From 141 P2P sim.papers, 30\% use a custom tool, \alert{50\% don't report
      used tool}\\ \medskip

    \end{column}
    \begin{column}{.33\linewidth}
      \includegraphics[width=\linewidth]{images/naicken.pdf}
    \end{column}
  \end{columns}

  \bottomcite{Collberg, Christian \textit{et Al.}, \textit{Measuring
      Reproducibility in Computer Systems Research},
    \url{http://reproducibility.cs.arizona.edu/}}

  \begin{columns}
    \begin{column}{.5\linewidth}
      ~\hspace{-1.7em}\includegraphics[height=4.7cm]{images/repeatability_arizona.pdf}
    \end{column}
    \begin{column}{.5\linewidth}
      \small
      \begin{itemize}
      \item 8 ACM conferences ({\scriptsize ASPLOS'12, CCS'12, OOPSLA'12, OSDI'12,
        PLDI'12, SIGMOD'12, SOSP'11, VLDB'12}) and 5 journals
      \item 
        $\text{EM}^{\text{no}}$= \alert{the code cannot be provided}
      \end{itemize}
    \end{column}
  \end{columns}
#+END_LaTeX

*** The Dog Ate my Homework !!!
#+BEGIN_LaTeX
  \vspace{-.4cm}
  \begin{multicols}{2}
    \begin{itemize}[<+->]
    \item \alert<.>{Versioning Problems}
    \item \alert<.>{Bad Backup Practices}
    \item \alert<.>{Code Will be Available Soon}
    \item \alert<.>{No Intention to Release}
    \item \alert<.>{Programmer Left}
    \item \alert<.>{Commercial Code}
    \item \alert<.>{Proprietary Academic Code}
    \item \alert<.>{Research vs. Sharing}
    \item<.-> ...
    \item<.-> ...
    \end{itemize}
  \end{multicols}
%  \vspace{-.5cm}

  \begin{block}{}
  \vspace{-.4cm}
  \begin{overlayarea}{\linewidth}{5cm}
      \small
      \only<1>{
        \begin{quote}
          Thanks for your interest in the implementation of our
          paper. The good news is that I was able to find some code. I
          am just \alert{hoping} that \alert{it} is a stable working
          version of the code, and \alert{matches the implementation we
            finally used for the paper}. Unfortunately, I have
          \alert{lost some data} when \alert{my laptop was stolen} last
          year. The bad news is that the code is not commented and/or
          clean.
        \end{quote}
        \begin{quote}
          Attached is the $\langle$system$\rangle$ source code of our
          algorithm. I’m \alert{not} very \alert{sure whether it is the
            final version of the code used in our paper}, but it should
          be at least 99\% close. Hope it will help.
        \end{quote}}%
      \only<2>{
        \begin{quote}
          Unfortunately, the server in which my implementation was
          stored had a \alert{disk crash in April and three disks
            crashed simultaneously}. While the help desk made
          significant effort to save the data, my entire implementation
          for this paper was not found.
        \end{quote}}
      \only<3>{
        \begin{quote}
          Unfortunately the
          current system is \alert{not mature enough at the moment}, so
          it’s not yet publicly available. We are actively working on a
          number of extensions and \alert{things are somewhat
            volatile}. However, once things stabilize we plan to release
          it to outside users. At that point, we would be happy to send
          you a copy.
        \end{quote}}%
      \only<4>{
        \begin{quote}
          I am afraid that the source code was never released. The code
          was \alert{never intended to be released so is not in any shape
            for general use}.
        \end{quote}}%
      \only<5>{
        \begin{quote}
          $\langle$STUDENT$\rangle$ was a graduate student in our
          program but \alert{he left a while back} so I am responding
          instead. For the paper we used a prototype that included many
          moving pieces that only $\langle$STUDENT$\rangle$ knew how to
          operate and we did not have the time to integrate them in a
          ready-to-share implementation before he left. Still, I hope
          you can build on the ideas/technique of the paper. 
        \end{quote}
        \begin{quote}
          Unfortunately, the author who has done most of the coding for
          this paper has \alert{passed away} and the code is no longer
          maintained.
        \end{quote}
      }%
      \only<6>{
        \begin{quote}
          Since this work has been done at $\langle$COMPANY$\rangle$
          \alert{we don't open-source code} unless there is a compelling
          business reason to do so. So unfortunately I don’t think we’ll
          be able to share it with you.
        \end{quote}
        \begin{quote}
          The code \alert{owned by $\langle$COMPANY$\rangle$}, and AFAIK
          the code is not open-source.  Your best bet is to reimplement
          :( Sorry.
        \end{quote}}%
      \only<7>{
        \begin{quote}
          Unfortunately, the $\langle$SYSTEM$\rangle$
          sources are \alert{not meant to be opensource} (the code is partially
          \alert{property of $\langle$UNIVERSITY 1$\rangle$,
            $\langle$UNIVERSITY 2$\rangle$ and $\langle$UNIVERSITY
            3$\rangle$.})

          If this will change I will let you know, albeit I do not
          think there is an intention to make the
          $\langle$SYSTEM$\rangle$ sources opensource in the near
          future.
        \end{quote}
        \begin{quote}
          If you're interested in obtaining the code, \alert{we only ask
            for a description of the research project} that the code
          will be used in (\alert{which may lead to some joint
            research}), and we also have a software license agreement
          that the University would need to sign.
        \end{quote}}
      \only<8>{
        \begin{quote}
          In the past when we attempted to share it, we found ourselves
          spending more time getting outsiders up to speed than on our
          own research. So \alert{I finally had to establish the policy
            that we will not provide the source code outside the group}.
        \end{quote}
      }
    \end{overlayarea}
  \end{block}
  \null\vspace{-.4cm}
#+END_LaTeX
* The Reproducible Research Movement
** How does it work in other sciences?
\includeslidesJF{2-7}
# \includeslidesJF{11-14}
# \includeslidesMG{26}
*** A few Words on Scientific Foundation
- *Falsifiability* or *refutability* of a statement, hypothesis, or
  theory is an inherent possibility to prove it to be false (not
  "/commit fraud/" but "/prove to be false/").
- Karl Popper makes falsifiability the demarcation criterion to
  *distinguish the scientific from the unscientific*

  #+BEGIN_QUOTE
  It is not only not right, it is not even wrong!

  -- Wolfgang Pauli
  #+END_QUOTE
- Theories cannot be proved correct but they can be disproved. Only a
  few stand the test of batteries of *critical experiments*.
- It is not all black and white. There are many stories where
  scientists stick with their theories despite evidences and
  sometimes, they were even right to do so...
#+BEGIN_CENTER
  *Testing and checking is thus one of the basis of science*
#+END_CENTER

Further readings: *A Summary of Scientific Method*, Peter Kosso,
Springer
*** Why Are Scientific Studies so Difficult to Reproduce?
#+LaTeX: \begin{overlayarea}{\linewidth}{7.6cm}\null\vspace{1cm}
- Copyright/competition issue
- Publication *bias* (only the idea matters, not the gory details)
- Rewards for *positive results*
- Experimenter *bias*
- Programming *errors* or data manipulation *mistakes*
- Poorly selected statistical tests
- Multiple testing, multiple looks at the data, multiple
  statistical analyses
- +*Lack of easy-to-use tools*+

#+LaTeX: \end{overlayarea} \begin{flushright}\scriptsize Courtesy of Adam J. Richards\end{flushright}
*** Evidence for a Lack of Reproducibility
#+LaTeX: \begin{overlayarea}{\linewidth}{7.6cm}\null\vspace{.6cm}
- Studies showing that scientific papers commonly *leave out
  experimental details essential for reproduction* and showing
  *difficulties with replicating published experimental results*:
  + J.P. Ioannidis. /[[http://www.plosmedicine.org/article/info:doi/10.1371/journal.pmed.0020124][Why Most Published Research Findings Are False]]/ PLoS
    Med. 2005 August; 2(8)
- High number of *failing clinical trials*.
  + /[[http://mescal.imag.fr/membres/arnaud.legrand/teaching/2011/EP_epidemiology.pdf][Do We Really Know What Makes Us Healthy?]]/, New-York Times —
    September 16, 2007
  + /[[http://mescal.imag.fr/membres/arnaud.legrand/teaching/2011/EP_lies.pdf][Lies, Damned Lies, and Medical Science]]/, The Atlantic. 2010, Nov.
- Increase in *retracted papers*:
  + Steen RG, /[[http://dx.doi.org/10.1136/jme.2010.040923][Retractions in the scientific literature: is the
    incidence of research fraud increasing?]]/ J Med Ethics 37:
    249–253.
#+LaTeX: \end{overlayarea} \begin{flushright}\scriptsize Courtesy of Adam J. Richards\end{flushright}
*** A Reproducibility Crisis?
#+LaTeX: \begin{overlayarea}{\linewidth}{7.6cm}\null\vspace{-.4cm}
*[[http://www.nytimes.com/2011/07/08/health/research/08genes.html][The Duke University scandal with scientific misconduct on lung
cancer]]*

\vspace{-.2cm}\small
- /Nature Medicine/ - 12, 1294 - 1300 (2006) *Genomic signatures to
  guide the use of chemotherapeutics*, by
  #+LaTeX: \bgroup\scriptsize
  Anil Potti and 16 other researchers from Duke University and
  University of South Florida
  #+LaTeX: \egroup\vspace{-.2cm}
- Major commercial labs licensed it and were about to start using it
  before two statisticians discovered and publicized its faults
  #+BEGIN_LaTeX
  \begin{block}{}\scriptsize
  Dr. Baggerly and Dr. Coombes found errors almost immediately. Some seemed careless — moving a row or a column over by one in a giant spreadsheet — while others seemed inexplicable. The Duke team shrugged them off as “clerical errors.”
  \end{block}

  \begin{block}{}\scriptsize
  The Duke researchers continued to publish papers on their genomic signatures in prestigious journals. Meanwhile, they started three trials using the work to decide which drugs to give patients.
  \end{block}
  #+END_LaTeX
- Retractions: January 2011. [[http://en.wikipedia.org/wiki/Anil_Potti][Ten papers that Potti coauthored in
  prestigious journals were retracted for varying reasons]]
- Some people die and may be getting worthless information that is
  based on *bad science*
#+LaTeX: \end{overlayarea} \begin{flushright}\scriptsize Courtesy of Adam J. Richards\end{flushright}
*** Definitely
- A recent scandal ::
  In 2013, [[https://en.wikipedia.org/wiki/Dong-Pyou_Han][/Dong-Pyou Han/]], a former assistant professor of biomedical
     sciences at Iowa State University was disgraced:\footnotesize
  - Falsified blood results to make it appear as though a vaccine he was
    working on had exhibited anti-HIV activity
  - Han and his team received $\approx$ \$19 million from NIH
  - Retraction and resignation of university
  - Han was sentenced in 2015 to 57 months imprisonment for
    fabricating and falsifying data in HIV vaccine trials. He was also
    fined US \$7.2 million!
- \normalsize We should avoid witch-hunt :: 
  #+LaTeX: ~\footnotesize
  - August 5, 2014, Yoshiki Sasai (stem cell, considered for Nobel
    Prize) hanged in his laboratory at the RIKEN
    (Japan). Fraud suspicion...
  - In 1986, a young postdoctoral fellow at MIT accused her director,
    Thereza Imanishi-Kari, of falsifying the results of a study
    published in Cell and co-signed by the Nobel laureate David
    Baltimore. [..] Declared guilty, Univ. presidency resignation, and
    finally cleared. This put the careers of two outstanding
    researchers on hold for ten years based on unfounded accusations.
- \normalsize Scientific fraud is bad but let's be careful :: \footnotesize Have a look at the
     wikipedia [[https://en.wikipedia.org/wiki/Category:Academic_scandals][/list of academic scandals/]]. On a totally different
     aspect, do not forget to also have a look at the [[https://en.wikipedia.org/wiki/Plagiarism][/plagiarism/]] and
     [[https://en.wikipedia.org/wiki/Paper_generator][/paper generation/]] entries at [[https://hal.inria.fr/file/index/docid/713564/filename/TechReportV2.pdf][/having fun with h-index/]]
#+BEGIN_CENTER
   [[http://www.cnrs.fr/fr/pdf/cim/CIM36.pdf][/The Battle against Scientific Fraud/ in the CNRS International
   Magazine]]
#+END_CENTER
*** Is Fraud a new phenomenon?
#+BEGIN_LaTeX
  \begin{columns}
    \begin{column}{.4\linewidth}
      \includegraphics[width=\linewidth]{images/CNRS_CIM_36_biomed_fraud.png}
    \end{column}
    \begin{column}{.6\linewidth}
   
      \begin{center}
        \includegraphics[width=.7\linewidth]{images/CNRS_CIM_36_scientists.pdf}
      \end{center}

#+END_LaTeX

- Galileo (data fabrication), Ptolemy (plagiarism), Mendel (data
  enhancement), [[http://lascienceenfraude.blogspot.fr/2012/05/limposture-de-pasteur.html][Pasteur]] (rigorous but hided failures), ...
#+BEGIN_LaTeX
    \end{column}
  \end{columns}
#+END_LaTeX
** Is CS Concerned Really With This?
*** My Feeling
Computer scientists have an incredibly *poor training in
probabilities, statistics, experiment management*
  
\medskip

Why should we? Computer are *deterministic* machines after all, right?
;)

\medskip

Ten years ago, I've started realizing how *lame* the articles I
reviewed (as well as those I wrote) were in term of experimental
methodology.
+ Yeah, I know, your method/algorithm is better than the others as
  demonstrated by the figures
+ Not enough information to *discriminate real effects from noise*
+ Little information about the *workload*
+ Would the ``conclusion'' still hold with a slightly different
  workload?
+ I'm tired of awful combination of tools (perl, gnuplot, sql, ...)
  and *bad methodology*
*** Common practice in CS
\small
Computer scientists tend to either:
- vary *one factor at a time*, use a very fine sampling of the
  parameter range,
- *run millions of experiments* for a week varying a lot of
  parameters and then try to get something of it. Most of the time,
  they (1) don’t know how to analyze the results (2) realize
  something went wrong...
#+BEGIN_LaTeX
\vspace{-1em}
\centerline{\begin{minipage}{.7\linewidth}
  \begin{block}{}Interestingly, most other scientists do \structure{the exact
  opposite}.
  \end{block}
\end{minipage}}
\vspace{.5em}
#+END_LaTeX

These two flaws come from poor training and from the fact that C.S.
experiments are *almost* free and very fast to conduct
- Most strategies of experimentation (DoE) have been designed to
  *provide sound answers despite* all the *randomness and
  uncontrollable factors*
- *Maximize the amount of information* provided by a given set of
  experiments
- *Reduce* as much as possible *the number of experiments* to perform
  to answer a given question under a given level of confidence
**** 
#+BEGIN_CENTER
Takes a few lectures on *Design of Experiments* to improve. But anyone
can start by reading *Jain's book on The Art of Computer Systems
Performance Analysis*
#+END_CENTER
\normalsize
*** But do we \textbf{really} have to care?
\small
*Yes*, although designed and built by human beings, computers are *so
complex* that mistakes are easy to do...

#+LaTeX: \begin{overlayarea}{1.07\linewidth}{1cm}\hspace{-.042\linewidth}\begin{minipage}{\linewidth}
- T. Mytkowicz, A. Diwan, M. Hauswirth, and P. F. Sweeney. *[[http://doi.acm.org/10.1145/1508284.1508275][Producing wrong data without doing anything obviously wrong]]!*. SIGPLAN Not. 44(3), March 2009
#+LaTeX: \end{minipage}\end{overlayarea}

#+BEGIN_LaTeX
\begin{overlayarea}{\linewidth}{4.4cm}
\begin{center}
\includegraphics<+>[width=.6\linewidth]{images/asplos09-producing-data_fig1.pdf}%
\includegraphics<+->[width=.6\linewidth]{images/asplos09-producing-data_fig2.pdf}%
\end{center}
\end{overlayarea}
#+END_LaTeX
**** Key principles of experiment design
- *Randomize* to *reduce bias*
- *Replicate* (possibly in a smart way) to *increase reliability*
** Reproducible Research/Open Science
*** Reproducible Research: the New Buzzword?
**** H2020-EINFRA-2014-2015
#+BEGIN_QUOTE
A key element will be capacity building to link literature and data in
order to enable a more transparent evaluation of research and
*reproducibility* of results.
#+END_QUOTE
**** More and more workshops
#+LaTeX: \scriptsize
- [[http://www.eecg.toronto.edu/~enright/wddd/][Workshop on Duplicating, Deconstructing and Debunking (WDDD)]] ([[http://cag.engr.uconn.edu/isca2014/workshop_tutorial.html][2014 edition]])
- \normalsize *[[http://www.stodden.net/AMP2011/][Reproducible Research: Tools and Strategies for Scientific
  Computing]]* \scriptsize(2011)
- [[http://wssspe.researchcomputing.org.uk/][Working towards Sustainable Software for Science: Practice and
  Experiences]] (2013)
- *[[http://hunoldscience.net/conf/reppar14/pc.html][REPPAR'14: 1st International Workshop on Reproducibility in
  Parallel Computing]]*
- [[https://www.xsede.org/web/reproducibility][Reproducibility@XSEDE: An XSEDE14 Workshop]]
- [[http://www.occamportal.org/reproduce][Reproduce/HPCA 2014]]
  #+LaTeX: \item \href{http://www.ctuning.org/cm/wiki/index.php?title\%3DEvents:TRUST2014}{TRUST 2014}
# - [[http://www.ctuning.org/cm/wiki/index.php?title%3DEvents:TRUST2014][TRUST 2014]]
\normalsize 
Should be seen as opportunities to share experience.
*** Reproducibility: What Are We Talking About?
#+BEGIN_LaTeX
\vspace{-.6em}
\begin{overlayarea}{\linewidth}{9cm}
\hbox{\hspace{-.05\linewidth}\includegraphics[page=5,width=1.1\linewidth]{pdf_sources/sumatra_amp2011.pdf}}

\vspace{-2cm}
\begin{flushright}
  {\scriptsize Courtesy of Andrew Davison (AMP Workshop on Reproducible research)}
\end{flushright}
\end{overlayarea}
#+END_LaTeX
*** Reproducible Research: Trying to Bridge the Gap
#+BEGIN_LaTeX
  \hbox{\hspace{-.05\linewidth}%
  \includegraphics<1>[width=1.07\linewidth,subfig=1]{fig/author_reader_rr.fig}%
  \includegraphics<2>[width=1.07\linewidth,subfig=2]{fig/author_reader_rr.fig}%
  \includegraphics<3>[width=1.07\linewidth,subfig=3]{fig/author_reader_rr.fig}%
  \includegraphics<4>[width=1.07\linewidth,subfig=4]{fig/author_reader_rr.fig}%
  \hspace{-.05\linewidth}}
\vspace{-.4cm}
\begin{flushright}
{\scriptsize {\textbf{Inspired by Roger D. Peng's lecture on reproducible research, May 2014}}}
\end{flushright}

In this series of lectures, we'll go from right to left and see how we can improve.
#+END_LaTeX
*** Mythbusters: Science vs. Screwing Around                        :B_frame:
    :PROPERTIES:
    :BEAMER_env: frame
    :BEAMER_OPT: plain
    :END:

#+BEGIN_LaTeX
\begin{overlayarea}{\linewidth}{0cm}
\vspace{-4cm}
\hbox{\hspace{-.1\linewidth}\includegraphics[width=1.2\linewidth,height=9cm]{images/remember_kids.jpg}}
\end{overlayarea}
#+END_LaTeX
*** A Difficult Trade-off
#+BEGIN_CENTER
Many different tools/approaches developed in various communities
#+END_CENTER

But mainly two approaches:
**** Automatically keeping track of everything
- the code that was run (source code, libraries, compilation
  procedure)
- processor architecture, OS, machine, date, ...
#+LaTeX: \vspace{-\baselineskip}
#+BEGIN_CENTER
*VM-based solutions* and *experiment engines*
#+END_CENTER
**** Ensuring others can understand/adapt what was done
- Why did I run this?
- Does it still work when I change this piece of code for this one?
#+LaTeX: \vspace{-\baselineskip}
#+BEGIN_CENTER
*Laboratory notebook* and *recipes*
#+END_CENTER
** Interesting Approaches for [PD]C Reproducible experiments
*** A few Experiment Management Tools
- Naive way: sh + ssh + ... \medskip
  #+BEGIN_LaTeX
  \item \alert<1>{Expo} (2007-, G5K)
  \item \alert<1>{XPflow} (2012-, G5K)
  \begin{overlayarea}{3cm}{0cm}
  \vspace{-2.5\baselineskip}
  $\left\}\begin{array}{l}
   \text{\phantom{X}}\\\text{\phantom{X}}\\\text{\phantom{X}}
   \end{array}\right.\hspace{-.7cm}
   \begin{array}{l}
   \text{although nothing} \\ \text{specific to G5K}
   \end{array}$
  \end{overlayarea}
  \item \alert<1>{Execo} (2013-, G5K) \medskip
  #+END_LaTeX
- Plush (2006-, PlanetLab)
- OMF (2009-, Wireless testbeds and Planetlab)
- Splay (2008, distributed algorithm comparison)
- ...

They differ in the underlying paradigms and the platforms for which
they have been designed

- *A taxonomy of experiment management tools for distributed
  systems*, T. Buchert, C. Ruiz , L. Nussbaum, O. Richard, FGCS, 2014
*** Expo
- Grenoble (B. Videau, C. Ruis, O. Richard) \hfill
  http://expo.gforge.inria.fr/
- *DSL* (Domain Specific Language) derived from *Ruby* and adapted to
  the management of experiment (based on *taktuk*, i.e., sh + ssh)
- At the moment Expo interacts with *Planetlab* and *Grid5000* testbeds
- Resource and task abstractions, client-server organization,
  *interactive* or *batch* mode
- *Native logging and archiving capabilities* 
  + every action performed on tasks, error flows, dates, ...
  + lets you know *what* was run, *when*, *where* and *how*
  #+LaTeX:\scriptsize
  #+BEGIN_SRC 
reserv=ExpoEngine::new(@connection)
reserv.site=["bordeaux","lille","luxembourg","nancy","sophia"]
reserv.resources=["nodes=50","nodes=10","nodes=4","nodes=4","nodes=30"]
reserv.name = "Expo Scalability"
reserv.walltime=600

reserv.run!
ptask $all, "hostname"
reserv.stop!
  #+END_SRC
  #+LaTeX: \normalsize
- Inspired similar tools like *[[http://execo.gforge.inria.fr/][/Execo/]]* that provides a *Python*-based
  API. Script-oriented, fork+sh+ssh or taktuk
*** XPflow
- Nancy (T. Buchert, L. Nussbaum)\hfill http://xpflow.gforge.inria.fr/
- *DSL* (Domain Specific Language) derived from *Ruby* and adapted to
  the management of experiment
- Resources, process, and activities 
- Top-down rather than bottom-up: *business process management*
- Cope with *failures* through *snapshots* and retry *policy*
#+BEGIN_LaTeX
\vspace{-.3em}
\begin{overlayarea}{\linewidth}{5cm}
\begin{center}
%\fbox{
   \includegraphics<+>[page=46,width=.9\linewidth,clip=true,bb=0 0 350 210 ]{./pdf_sources/xpflow_slides.pdf}%
   \includegraphics<+>[page=47,width=.9\linewidth,clip=true,bb=0 0 350 210 ]{./pdf_sources/xpflow_slides.pdf}%
   \includegraphics<+>[page=48,width=.9\linewidth,clip=true,bb=0 0 350 210 ]{./pdf_sources/xpflow_slides.pdf}%
   \includegraphics<+>[page=49,width=.9\linewidth,clip=true,bb=0 0 350 210 ]{./pdf_sources/xpflow_slides.pdf}%
   \includegraphics<+>[page=50,width=.9\linewidth,clip=true,bb=0 0 350 210 ]{./pdf_sources/xpflow_slides.pdf}%
   \includegraphics<+>[page=51,width=.9\linewidth,clip=true,bb=0 0 350 210 ]{./pdf_sources/xpflow_slides.pdf}%
%}
\end{center}
\vspace{-2.7cm}
\begin{flushright}
  {\scriptsize {\textbf{Courtesy of T. Buchert\qquad\null}}}
\end{flushright}
\end{overlayarea}
#+END_LaTeX 
*** A few Environment Management Tools
CDE automatically tracks and packages up the Code, Data, and
Environment 

#+BEGIN_CENTER
  Providing *not only VMs or binaries* but also *recipes* is *good*!
#+END_CENTER

E.g., the Kameleon project

- Univ. Grenoble (C. Ruiz, S. Harrache, M. Mercier, O. Richard, ...)
  #+BEGIN_CENTER
  http://kameleon.readthedocs.org/
  #+END_CENTER
- Generate customized *appliances* (kvm, LXC, Virtualbox, iso, ...)
- Ruby-based, *YAML* description of *recipes* with *steps* and
  *aliases*, execution in *contexts*
- Automatically *checkpoints* to rebuild only what is required
** Many Different Alternatives for Replicable Analysis
*** Vistrails: a Workflow Engine for Provenance Tracking
#+BEGIN_LaTeX
\vspace{-.6em}
\begin{overlayarea}{\linewidth}{9cm}
\hbox{\hspace{-.05\linewidth}%
\includegraphics<+>[page=14,width=1.1\linewidth]{pdf_sources/2011-amp-reproducible-research.pdf}%
\includegraphics<+>[page=15,width=1.1\linewidth]{pdf_sources/2011-amp-reproducible-research.pdf}%
}

\vspace{-2cm}
\begin{flushright}
  {\scriptsize Courtesy of Juliana Freire (AMP Workshop on
    Reproducible research)}
\end{flushright}
\end{overlayarea}
#+END_LaTeX
*** VCR: A Universal Identifier for Computational Results
#+BEGIN_LaTeX
\vspace{-.6em}
\begin{overlayarea}{\linewidth}{9cm}
\hbox{\hspace{-.05\linewidth}%
\includegraphics<+>[page=76,width=1.1\linewidth]{pdf_sources/amp-ver1MATAN.pdf}%
\includegraphics<+>[page=78,width=1.1\linewidth]{pdf_sources/amp-ver1MATAN.pdf}%
\includegraphics<+>[page=113,width=1.1\linewidth]{pdf_sources/amp-ver1MATAN.pdf}%
\includegraphics<+>[page=26,width=1.1\linewidth]{pdf_sources/amp-ver1MATAN.pdf}%
}

\vspace{-2cm}
\begin{flushright}
  {\scriptsize Courtesy of Matan Gavish and David Donoho (AMP Workshop on
    Reproducible research)}
\end{flushright}
\end{overlayarea}
#+END_LaTeX 
*** Sumatra: an "experiment engine" that helps taking notes
#+BEGIN_LaTeX
\vspace{-.6em}
\begin{overlayarea}{\linewidth}{9cm}
\hbox{\hspace{-.05\linewidth}%
\includegraphics<+>[page=35,width=1.1\linewidth]{pdf_sources/sumatra_amp2011.pdf}%
\includegraphics<+>[page=39,width=1.1\linewidth]{pdf_sources/sumatra_amp2011.pdf}%
\includegraphics<+>[page=40,width=1.1\linewidth]{pdf_sources/sumatra_amp2011.pdf}%
\includegraphics<+>[page=46,width=1.1\linewidth]{pdf_sources/sumatra_amp2011.pdf}%
}

\vspace{-2cm}
\begin{flushright}
  {\scriptsize Courtesy of Andrew Davison (AMP Workshop on
    Reproducible research)}
\end{flushright}
\end{overlayarea}
#+END_LaTeX
*** So many new tools
#+BEGIN_LaTeX
\vspace{-.6em}
\begin{overlayarea}{\linewidth}{9cm}
\hbox{\hspace{-.05\linewidth}%
\includegraphics[page=13,width=1.1\linewidth]{pdf_sources/DavisFeb132014-STODDEN.pdf}%
}
\vspace{-1.5cm}
\begin{flushright}
  {\scriptsize {\textbf{Courtesy of Victoria Stodden (UC Davis, Feb 13, 2014)}}}
\end{flushright}
\vspace{.8cm}
And also: \textbf{Figshare}, \textbf{ActivePapers}, \textbf{Elsevier executable paper}, ...
\end{overlayarea}
#+END_LaTeX 
* Reporting Results
** An IMRAD Report
*** Structure
Research articles are often structured in this basic order:
- Introduction ::  Why was the study undertaken? What was the research
                   question, the tested hypothesis or the purpose of
                   the research?
- Methods :: When, where, and how was the study done? What
             materials/hardware were used? How was it configured?
- Results :: What answer was found to the research question; what did
             the study find? Was the tested hypothesis true? *Present
             useful results in a synthetic way with a logical order*.
- Discussion :: What might the answer imply and why does it matter?
                How does it fit in with what other researchers have
                found? What are the possible bias and points to
                improve? What are the perspectives for future
                research?

Such structure *facilitates literature review* and is a very effective
way to convey information.

If the report is a few pages long then *an abstract is required*.
** Good Practice for Setting up a Laboratory Notebook
*** Step 0: Taking Notes
*Document* your:
+ *Hypotheses*: keep track of your ideas/line of thoughts
+ *Experiments*: details on how and why an experiment was run, including
  failed or ambiguous attempts.
+ *Initial analysis or interpretation* of these experiments: was the
  outcome conform to the expectation or not? does it (in)validate the
  hypothesis?
+ *Organization*: keep track of things to do/fix/test/improve

*Structure*:
1. General information about the document and organization *conventions*
   (e.g., directory structure, notebook structure, experimental result
   storing mechanism, ...)
2. Documentation of *commonly used commands* and of how to set up
   experiments (e.g., git cloning, environment deployment, connection
   to machines, compiling scripts)
3. Experiment results can be either structured *by dates* ($\leadsto$ add
   tags) or *by experiment campaigns* ($\leadsto$ add date/time)
*** Which format should I use ?
- *Wikis* are encouraged to favor collaboration but I do not find them
  really effective
- *Blogging* systems are also a way of managing such notebook but they
  should rather be considered as an effective way to share information
  with others
- I recommend to use basic *plain-text* format and to *structure it
  hierarchically*
  #+BEGIN_CENTER 
  Here is a *[[http://starpu-simgrid.gforge.inria.fr/misc/LabBook.html\#sec-8-1][link]]* to an excerpt of the journal of one of my PhD
  student, managed with git/org-mode. More detailed links are given in
  #+LaTeX: slide~\ref{orglabref}.
  #+END_CENTER

Last but not least:
#+BEGIN_CENTER
Provide links to *Raw Data*!!!
#+END_CENTER
*** When/How Often Should I Use it?
I have a very intense usage (demo to *[[file:~/org/journal.org][general journal]]* and specific
*[[file:~/Work/Documents/Articles/2013/2013_boinc_response_time_optimization/journal.org][BOINC journal]]*) and I tend to capture a lot of information but you do
not have to be as extreme as I am. Here are a few advices:

- Spending *more than an hour without* at least *writing* what you're
  working on *is not right*...
  + *Take a 5 minutes* break and ask yourself what you're doing, what is
    keeping you busy and where all this is leading you
- While working on something, you will often notice/think about
  something you should fix/improve but you just don't want to do it
  now. Take 20 seconds to write a *TODO* entry.
- There are moments where you have to *wait for something* (compiling,
  deployment, ...). It is generally the perfect time for improving
  your notes (e.g., detail the steps to accomplish a TODO entry).
- *By the end of the day*: daily (and weekly) *review!*
  - Update your lists, write what the next steps are
  - *Summarize in a 2-4 lines* (for your advisor) what you did, what was
    difficult, what you learnt.
*** Step 1: Sharing Code and Data
#+LaTeX: \begin{overlayarea}{\linewidth}{7.6cm}\null\vspace{-.6cm}
#+LaTeX: \begin{block}{What kinds of systems are available?}
- "Good" - The cloud (Dropbox, Google Drive, *Figshare*)
- *Better* - Version control systems (SVN, *Git* and Mercurial)
- "Best" - Version control systems on the cloud (GitHub, Bitbucket)

Depends on the level of privacy you expect but you probably already
know these tools. 
#+LaTeX: \hfill\textbf{\bf Few handle GB files}...\hfill\null
#+LaTeX: \end{block}\begin{block}{Is this enough?}
1. Use a workflow that *documents both data and process*
2. Use the machine readable *CSV format*
3. Provide *raw* data and *meta* data, not just statistical outputs
4. *Never* do data manipulation and statistical tests *by hand*
5. *Use R*, Python or another free software to read and process raw
   data (*ideally* to *produce complete reports* with code, results
   and prose)
#+LaTeX: \end{block}

#+LaTeX: \end{overlayarea} \begin{flushright}\scriptsize Courtesy of Adam J. Richards\end{flushright}
*** Step 2: Literate Programming
\small
*Donald Knuth*: explanation of the program logic in a *natural language*
*interspersed with snippets of* macros and traditional *source code*.

#+BEGIN_CENTER
I'm way too =3l33t= to program this way but that's \\
*exactly what we need for writing a reproducible article/analysis!*
#+END_CENTER
#+LaTeX: \vspace{-.5em}

**** Org-mode (requires emacs)
My favorite tool.
- plain text, very smooth, works both for html, pdf, ...
- allows to combine all my favorite languages even with sessions
**** Ipython notebook
If you are a python user, go for it! Web app, easy to use/setup...
**** KnitR (a.k.a. Sweave)
For non-emacs users and as a first step toward /reproducible papers/:
- Click and play with a modern IDE (e.g., Rstudio)
* R/knitr Crash Course
** General Introduction
*** Why R?
R is a great language for data analysis and statistics
- Open-source and multi-platform
- Very expressive with high-level constructs
- Excellent graphics
- Widely used in academia and business
- Very active community
  + Documentation, FAQ on http://stackoverflow.com/questions/tagged/r
- Great integration with other tools
*** Why is such R a pain for computer scientists?
- R is *not* really a *programming* language
- Documentation is for statisticians
- Default plots are +cumbersome+ (meaningful)
- Summaries are +cryptic+ (precise)
- *Steep learning curve* even for us, computer scientists whereas we
  generally switch seamlessly from a language to another!  That's
  frustrating! ;)
*** Do's and dont's
+R is high level, I'll do everything myself+
- CTAN comprises 4,334 TeX, LaTeX, and related packages and
  tools. Most of you do not use plain TeX.
- Currently, the CRAN package repository features 4,030 available
  packages.
- How do you know which one to use??? Many of them are highly
  exotic (not to say useless to you).
  #+BEGIN_CENTER
  I learnt with http://www.r-bloggers.com/
  #+END_CENTER
	

- Lots of introductions but not necessarily what you're looking
  for so *I'll give you a short tour*. 

  You should quickly realize though that you need proper training
  in statistics and data analysis if you do not want tell
  nonsense.

- Again, you should read *Jain's book on The Art of Computer Systems
  Performance Analysis*

- You may want to *follow online courses*:
  + https://www.coursera.org/course/compdata
  + https://www.coursera.org/course/repdata
*** Install and run R on debian
\small
#+begin_src sh
apt-cache search r
#+end_src
Err, that's not very useful :) It's the same when searching on
google but once the filter bubble is set up, it gets better...
#+begin_src sh
sudo apt-get install r-base
#+end_src

#+BEGIN_SRC sh :results output :exports both :session
R
#+END_SRC

#+RESULTS:

\scriptsize
#+RESULTS:
#+begin_example
R version 3.2.0 (2015-04-16) -- "Full of Ingredients"
Copyright (C) 2015 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> 
#+end_example

*** Install a few cool packages
R has it's own package management mechanism so just run R and type the
following commands:
- =ddply=, =reshape= and =ggplot2= by Hadley Wickham (http://had.co.nz/)
  #+begin_src R
  install.packages("plyr")    
    # or better: install.packages("dplyr")
  install.packages("reshape") 
    # or better; install.packages("tidyr")
  install.packages("ggplot2")
  #+end_src
- =knitR= by (Yihui Xie) http://yihui.name/knitr/
  #+begin_src R
  install.packages("knitr")
  #+end_src
*** IDE
Using R interactively is nice but quickly becomes painful so at some
point, you'll want an IDE.

\medskip

Emacs is great but you'll need /Emacs Speaks Statistics/
#+begin_src sh
sudo apt-get install ess
#+end_src
\medskip

#+BEGIN_CENTER
In this tutorial, I will briefly show you *rstudio*
(https://www.rstudio.com/) and later how to use =org-mode=
#+END_CENTER
** Reproducible Documents: knitR
*** Rstudio screenshot
#+BEGIN_LaTeX
\vspace{-.5cm}
\begin{center}
  \includegraphics[height=9cm]{./images/rstudio_shot.png}
\end{center}
#+END_LaTeX
*** Reproducible analysis in Markdown + R
- Create a new *R Markdown* document (Rmd) in rstudio
- R chunks are interspersed with =```{r}= and =```=
- Inline R code: =`r sin(2+2)`=
- You can *knit* the document and share it via *rpubs*
- R chunks can be sent to the top-level with =Alt-Ctrl-c=
- I usually work mostly with the current environment and only knit in
  the end
- Other engines can be used (use rstudio *completion*)
  #+BEGIN_SRC 
  ```{r engine='sh'}
  ls /tmp/
  ```
  #+END_SRC
- Makes *reproducible analysis as simple as one click*
- Great tool for quick analysis for self and colleagues, homeworks, ...
*** Reproducible articles with LaTeX + R
- Create a new *R Sweave* document (Rnw) in rstudio
- R chunks are interspersed with 
  #+LaTeX: \texttt{<\null<>\null>=} 
  and =@=
- You can *knit* the document to produce a pdf
- You'll probably quickly want to *change default behavior* (activate
  the cache, hide code, ...). In the preembule:
  #+BEGIN_EXAMPLE
  <<echo=FALSE>>=
  opts_chunk$set(cache=TRUE,dpi=300,echo=FALSE,fig.width=7,
                  warning=FALSE,message=FALSE)
  @
  #+END_EXAMPLE
- Great for journal articles, theses, books, ...
** Introduction to R
*** Data frames
\small
#+begin_src R :results output :session :exports none
library(ggplot2)
library(plyr)
#+end_src

#+RESULTS:

A data frame is a data tables (with columns and rows). =mtcars= is a
built-in data frame that we will use in the sequel
#+BEGIN_SRC R :results output :exports both :session
head(mtcars);
#+END_SRC

#+RESULTS:
:                    mpg cyl disp  hp drat    wt  qsec vs am gear carb
: Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4
: Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4
: Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1
: Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1
: Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2
: Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1

You can also load a data frame from a CSV file:
#+BEGIN_SRC R :results output :exports both :session
df <- read.csv("http://foo.org/mydata.csv", header=T, 
               strip.white=TRUE);
#+END_SRC
You will *get help* by using =?=:
#+BEGIN_SRC :results output :exports both :session
?data.frame
?rbind
?cbind
#+END_SRC
*** Exploring Content (1)
\small
#+BEGIN_SRC R :results output :exports both :session
names(mtcars);
#+END_SRC

#+RESULTS:
:  [1] "mpg"  "cyl"  "disp" "hp"   "drat" "wt"   "qsec" "vs"   "am"   "gear"
: [11] "carb"

#+BEGIN_SRC R :results output :exports both :session
str(mtcars);
#+END_SRC

#+RESULTS:
#+begin_example
'data.frame':	32 obs. of  11 variables:
 $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...
 $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...
 $ disp: num  160 160 108 258 360 ...
 $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...
 $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...
 $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...
 $ qsec: num  16.5 17 18.6 19.4 17 ...
 $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...
 $ am  : num  1 1 1 0 0 0 0 0 0 0 ...
 $ gear: num  4 4 4 3 3 3 3 4 4 4 ...
 $ carb: num  4 4 1 1 2 1 4 2 2 4 ...
#+end_example
*** Exploring Content (2)
\small
#+BEGIN_SRC R :results output :exports both :session
dim(mtcars);
length(mtcars);
#+END_SRC

#+RESULTS:
: [1] 32 11
: [1] 11

#+BEGIN_SRC R :results output :exports both :session
summary(mtcars);
#+END_SRC

#+RESULTS:
#+begin_example
      mpg             cyl             disp             hp       
 Min.   :10.40   Min.   :4.000   Min.   : 71.1   Min.   : 52.0  
 1st Qu.:15.43   1st Qu.:4.000   1st Qu.:120.8   1st Qu.: 96.5  
 Median :19.20   Median :6.000   Median :196.3   Median :123.0  
 Mean   :20.09   Mean   :6.188   Mean   :230.7   Mean   :146.7  
 3rd Qu.:22.80   3rd Qu.:8.000   3rd Qu.:326.0   3rd Qu.:180.0  
 Max.   :33.90   Max.   :8.000   Max.   :472.0   Max.   :335.0  
      drat             wt             qsec             vs        
 Min.   :2.760   Min.   :1.513   Min.   :14.50   Min.   :0.0000  
 1st Qu.:3.080   1st Qu.:2.581   1st Qu.:16.89   1st Qu.:0.0000  
 Median :3.695   Median :3.325   Median :17.71   Median :0.0000  
 Mean   :3.597   Mean   :3.217   Mean   :17.85   Mean   :0.4375  
 3rd Qu.:3.920   3rd Qu.:3.610   3rd Qu.:18.90   3rd Qu.:1.0000  
 Max.   :4.930   Max.   :5.424   Max.   :22.90   Max.   :1.0000  
       am              gear            carb      
 Min.   :0.0000   Min.   :3.000   Min.   :1.000  
 1st Qu.:0.0000   1st Qu.:3.000   1st Qu.:2.000  
 Median :0.0000   Median :4.000   Median :2.000  
 Mean   :0.4062   Mean   :3.688   Mean   :2.812  
 3rd Qu.:1.0000   3rd Qu.:4.000   3rd Qu.:4.000  
 Max.   :1.0000   Max.   :5.000   Max.   :8.000
#+end_example
*** Exploring Content (3)
\small
#+BEGIN_SRC R :results output graphics :file ./pdf_babel/mtcars_plot.pdf :exports both :session
plot(mtcars[names(mtcars) %in% c("cyl","wt","disp","qsec","gear")]);
#+END_SRC

#+ATTR_LaTeX: :width .6\linewidth
#+RESULTS:
[[file:./pdf_babel/mtcars_plot.pdf]]

*** Accessing Content
\small
#+BEGIN_SRC R :results output :exports both :session
mtcars$mpg
#+END_SRC

#+RESULTS:
:  [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16.4 17.3 15.2 10.4
: [16] 10.4 14.7 32.4 30.4 33.9 21.5 15.5 15.2 13.3 19.2 27.3 26.0 30.4 15.8 19.7
: [31] 15.0 21.4

#+BEGIN_SRC R :results output :exports both :session
mtcars[2:5,]$mpg
#+END_SRC

#+RESULTS:
: [1] 21.0 22.8 21.4 18.7

#+BEGIN_SRC R :results output :exports both :session
mtcars[mtcars$mpg == 21.0,]
#+END_SRC

#+RESULTS:
:               mpg cyl disp  hp drat    wt  qsec vs am gear carb
: Mazda RX4      21   6  160 110  3.9 2.620 16.46  0  1    4    4
: Mazda RX4 Wag  21   6  160 110  3.9 2.875 17.02  0  1    4    4

#+BEGIN_SRC R :results output :exports both :session
mtcars[mtcars$mpg == 21.0 & mtcars$wt > 2.7,]
#+END_SRC

#+RESULTS:
:               mpg cyl disp  hp drat    wt  qsec vs am gear carb
: Mazda RX4 Wag  21   6  160 110  3.9 2.875 17.02  0  1    4    4
*** Extending Content
\small
#+BEGIN_SRC R :results output :exports both :session
mtcars$cost = log(mtcars$hp)*atan(mtcars$disp)/
                 sqrt(mtcars$gear**5);
mean(mtcars$cost);
summary(mtcars$cost);
#+END_SRC

#+RESULTS:
: [1] 0.345994
:    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
:  0.1261  0.2038  0.2353  0.3460  0.5202  0.5534

#+BEGIN_SRC R :results output graphics :file ./pdf_babel/mtcars_hist.pdf :exports both :session
hist(mtcars$cost,breaks=20);
#+END_SRC

#+ATTR_LaTeX: :height 4.5cm
#+RESULTS:
[[file:./pdf_babel/mtcars_hist.pdf]]
*** Take away Message
- R is a great tool but is only a tool. There is no magic. You
  need to understand what you are doing and get a *minimal
  training in statistics*
- It is one of the building block of *reproducible research* (the
  /reproducible analysis/ block) and *will save you a lot of time*
- It provides you an access to any statistical method you ever dreamt
  of
- Read at least Jain's book: *The Art of Computer Systems Performance
  Analysis*
- There are introductory *online courses* (from John Hopkins university)
  on coursera which you may want to follow
* Emacs Demo of How to Keep Things Tidy
*** toc
#+BEGIN_LaTeX
    \frametitle{Outline}
    \tableofcontents[current,currentsubsection]
#+END_LaTeX
*** Literate Programming on a Daily Basis
**** Mastering Emacs
- =C-g=: get me out of here!
- =C-_=: undo
- Activate CUA keys in the Options menu
**** Mastering Org-mode
- =Tab= will fold/unfold stuff
- =C-c C-c=: do something (context-sensitive) where you are
- =<s= + =Tab=, =<b=, =<l=, =<r=, =<h=, ... for *creating code blocks*
- =C-c C-e=: *export*
- =C-c c=: *capture content*
- =C-c C-o= / =C-c l= / =C-c C-l=: open/store/insert *links*
- =C-c C-a=: *attach* a file
- =C-c C-d=: set deadline, =C-c C-t=: TODO/DONE

*** Emacs/Org-mode Recap
#+LaTeX: \label{orglabref}

**** Key features
- Plain text makes it *very robust* and *human readable*
- Allow to *mix any language* and has a notion of session that makes its
  use very effective
- Allow to produce both =html documents=, classical \LaTeX articles,
  \textsc{beamer} slides, =odt= documents, ... Native *pretty printing* on Github
**** A Few Links to Learn More
- /[[http://orgmode.org/worg/org-tutorials/org4beginners.html][Org for beginners]]/, /[[http://mescal.imag.fr/membres/arnaud.legrand/misc/init.org][my emacs configuration]]/ and /[[http://mescal.imag.fr/membres/arnaud.legrand/blog/2014/05/15/emacs_and_orgmode_on_macosx.php][tricks for Mac OS
  X users]]/
- A [[https://anonsvn:anonsvn@gforge.inria.fr/plugins/scmgit/cgi-bin/gitweb.cgi?p%3Dstarpu-simgrid/starpu-simgrid.git%3Ba%3Dblob%3Bf%3Drun_bench_StarPU.sh%3Bhb%3D41380b54a7#l220][/script/]] *capturing* and gathering many *information* into a 
  [[https://anonsvn:anonsvn@gforge.inria.fr/plugins/scmgit/cgi-bin/gitweb.cgi?p%3Dstarpu-simgrid/starpu-simgrid.git%3Ba%3Dblob%3Bf%3Ddata/dataK40/K40chol/SoloStarpuData10.org%3Bh%3D1655becd0a%3Bhb%3Drefs/heads/data][/*single result document*/]]
- A [[https://anonsvn:anonsvn@gforge.inria.fr/plugins/scmgit/cgi-bin/gitweb.cgi?p%3Dstarpu-simgrid/starpu-simgrid.git%3Ba%3Dblob%3Bf%3DLabbook.org%3Bh%3D01928ce013%3Bhb%3Drefs/heads/data#l272][/*laboratory notebook*/]] *with notes about all the experiments*
  performed since the beginning of the project
- [[https://anonsvn:anonsvn@gforge.inria.fr/plugins/scmgit/cgi-bin/gitweb.cgi?p%3Dstarpu-simgrid/starpu-simgrid.git%3Ba%3Dblob%3Bf%3DLabBook.org%3Bh%3D0b20e8abd5%3Bhb%3Drefs/heads/data#l950][/*Litterately conducting experiments*/]] using org-mode 
* To do for the Next Time
*** This was way too much information...

... but keep these slides in mind and re-read them later. You will
follow many links when you will realize what they can bring to you.

- We need to put all this in practice.
- During this semester, you will *learn how to improve your methodology*
- You will apply analysis and reporting techniques to a *simple use
  case*:
#+BEGIN_QUOTE
  One of your colleague just implemented a multi-threaded version of
  the quicksort algorithm for multi-core machines. He's convinced his
  code can save significant time saving but unfortunately, he did not
  follow the performance evaluation lecture and he would like your
  help to promote his code.
#+END_QUOTE
- After you have tried, we will *debrief* on what you did and *discuss
  how it could be improved*
*** To do for the Next Time (1/2)
1. *Install* R and Rstudio and all the packages I previously mentioned
   (=plyr=, =dplyr=, =reshape=, =tidyr=, =ggplot2=) on your own machines.
2. Make sure you know how to *create small reproducible analysis* and
   publish them on! [[http://rpubs.com][rpubs]] with Rstudio.
3. Start \alert{learn}ing *R* with [[http://swirlstats.com/students.html][/swirl/]]: You may want to have a look
   at [[http://cran.r-project.org/doc/contrib/Paradis-rdebuts_en.pdf][/R for Beginners/]].
4. *Setup* emacs *org-mode* and start playing with it.
*** To do for the Next Time (2/2)
1. *Fork* on Github and send me corresponding URL
   #+BEGIN_CENTER
   https://github.com/alegrand/M2R-ParallelQuicksort
   #+END_CENTER
2. Experiment this code on various environments (laptop, G5K, ...)
3. *Take notes on what you did* and push back your journal on github
4. Create a synthetic one page IMRAD report
